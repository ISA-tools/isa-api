{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a repeated treatment design with ISA descriptor\n",
    "\n",
    "This example creates `ISA study descriptor` for study with sequential treatments organized in an arm. \n",
    "This shows how to use objects from the `isatools.create` component in a granular fashion.\n",
    "It creates each `Element` of the Study `Arm` at a time.\n",
    "\n",
    "Finally, the `study design plan` is shown by serializing the `ISA Study Design Model` content as an  `ISA_design` JSON document, which can be rendered in various ways (tables, figures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If executing the notebooks on `Google Colab`,uncomment the following command \n",
    "# and run it to install the required python libraries. Also, make the test datasets available.\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from collections import OrderedDict\n",
    "from isatools.model import (\n",
    "    Investigation,\n",
    "    Study,\n",
    "    OntologyAnnotation,\n",
    "    Sample,\n",
    "    Characteristic,\n",
    "    ProtocolParameter,\n",
    "    ParameterValue,\n",
    "    StudyFactor,\n",
    "    FactorValue\n",
    ")\n",
    "\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Range1d, BoxAnnotation, Label, Legend, LegendItem, LabelSet\n",
    "from bokeh.models.tools import HoverTool\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "# hv.extension('bokeh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start by creating basic ISA Study metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "investigation = Investigation()\n",
    "study = Study(filename=\"s_study_xover.txt\")\n",
    "study.identifier = 'S-Xover-1'\n",
    "study.title = 'My Simple ISA Study'\n",
    "study.description = \"We could alternataly use the class constructor's parameters to set some default \" \\\n",
    "          \"values at the time of creation, however we want to demonstrate how to use the \" \\\n",
    "          \"object's instance variables to set values.\"\n",
    "study.submission_date = str(datetime.datetime.today())\n",
    "study.public_release_date = str(datetime.datetime.today())\n",
    "# study.sources = [Source(name=\"source1\")]\n",
    "# study.samples = [Sample(name=\"sample1\")]\n",
    "# study.protocols = [Protocol(name=\"sample collection\")]\n",
    "# study.process_sequence = [Process(executes_protocol=study.protocols[-1], inputs=[study.sources[-1]], outputs=[study.samples[-1]])]\n",
    "investigation.studies = [study]\n",
    "# investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from isatools.isatab import dumps\n",
    "# print(dumps(investigation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "# print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the new ISA create module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isatools.create.model import (\n",
    "    Treatment,\n",
    "    NonTreatment,\n",
    "    StudyCell,\n",
    "    StudyArm,\n",
    "    ProductNode,\n",
    "    ProtocolNode,\n",
    "    AssayGraph,\n",
    "    SampleAndAssayPlan,\n",
    "    StudyDesign\n",
    ")\n",
    "from isatools.create.constants import (\n",
    "    RUN_IN,\n",
    "    WASHOUT,\n",
    "    FOLLOW_UP,\n",
    "    SAMPLE,\n",
    "    EXTRACT,\n",
    "    DATA_FILE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creation of the first `ISA Study Design Element` and setting its type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonTreatment(\n",
      "            type='screen',\n",
      "            duration=isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='DURATION', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=0.0, unit=isatools.model.OntologyAnnotation(term='days', term_source=None, term_accession='', comments=[]))\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "nte1 = NonTreatment(element_type='screen', duration_unit=OntologyAnnotation(term=\"days\"))\n",
    "print(nte1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creation of another `ISA Study Design Element`, of type `Treatment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=biological intervention, \n",
      "        factor_values=[])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "te1 = Treatment()\n",
    "te1.type='biological intervention'\n",
    "print(te1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 defining the first treatment as a vector of ISA factor values:\n",
    "\n",
    "Under \"ISA Study Design Create mode\", a `Study Design Element` of type `Treatment` needs to be defined by a vector of `Factors` and their respective associated `Factor Values`. This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1 = StudyFactor(name='virus', factor_type=OntologyAnnotation(term=\"organism\"))\n",
    "f1v = FactorValue(factor_name=f1, value=\"hsv1\")\n",
    "f2 = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"quantity\"))\n",
    "f2v = FactorValue(factor_name=f2, value='high dose')\n",
    "f3 = StudyFactor(name='time post infection', factor_type=OntologyAnnotation(term=\"time\"))\n",
    "f3v = FactorValue(factor_name=f3, value=2, unit=OntologyAnnotation(term='hr'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=biological intervention, \n",
      "        factor_values=[isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='dose', factor_type=isatools.model.OntologyAnnotation(term='quantity', term_source=None, term_accession='', comments=[]), comments=[]), value='high dose', unit=None), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='time post infection', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=2, unit=isatools.model.OntologyAnnotation(term='hr', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='virus', factor_type=isatools.model.OntologyAnnotation(term='organism', term_source=None, term_accession='', comments=[]), comments=[]), value='hsv1', unit=None)])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "#assigning the factor values declared above to the ISA treatment element\n",
    "te1.factor_values = [f1v,f2v,f3v]\n",
    "print(te1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creation of a second  `ISA Study Design Element`, of type `Treatment`, following the same pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=chemical intervention, \n",
      "        factor_values=[isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='antiviral', factor_type=isatools.model.OntologyAnnotation(term='chemical entity', term_source=None, term_accession='', comments=[]), comments=[]), value='hsvflumab', unit=None), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='dose', factor_type=isatools.model.OntologyAnnotation(term='quantity', term_source=None, term_accession='', comments=[]), comments=[]), value=10, unit=isatools.model.OntologyAnnotation(term='mg/kg/day', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='treatment duration', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=2, unit=isatools.model.OntologyAnnotation(term='weeks', term_source=None, term_accession='', comments=[]))])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "te2 = Treatment()\n",
    "te2.type = 'chemical intervention'\n",
    "antivir = StudyFactor(name='antiviral', factor_type=OntologyAnnotation(term=\"chemical entity\"))\n",
    "antivirv = FactorValue(factor_name=antivir, value='hsvflumab')\n",
    "intensity = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"quantity\"))\n",
    "intensityv= FactorValue(factor_name=intensity, value = 10, unit=OntologyAnnotation(term='mg/kg/day'))\n",
    "duration =  StudyFactor(name = 'treatment duration', factor_type=OntologyAnnotation(term=\"time\"))\n",
    "durationv = FactorValue(factor_name=duration, value=2, unit=OntologyAnnotation(term='weeks'))\n",
    "te2.factor_values = [antivirv,intensityv,durationv]\n",
    "print(te2)\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Treatment\n",
      "        (type=radiological intervention, \n",
      "        factor_values=[isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='dose', factor_type=isatools.model.OntologyAnnotation(term='quantity', term_source=None, term_accession='', comments=[]), comments=[]), value='10', unit=isatools.model.OntologyAnnotation(term='mSev', term_source=None, term_accession='', comments=[])), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='radiation', factor_type=isatools.model.OntologyAnnotation(term='physical entity', term_source=None, term_accession='', comments=[]), comments=[]), value='neutron beam', unit=None), isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='treatment duration', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value='30', unit=isatools.model.OntologyAnnotation(term='minutes', term_source=None, term_accession='', comments=[]))])\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "te3 = Treatment()\n",
    "te3.type = 'radiological intervention'\n",
    "rays = StudyFactor(name='radiation', factor_type=OntologyAnnotation(term=\"physical entity\"))\n",
    "raysv = FactorValue(factor_name=rays, value='neutron beam')\n",
    "rays_intensity = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"quantity\"))\n",
    "rays_intensityv= FactorValue(factor_name=rays_intensity, value = '10', unit=OntologyAnnotation(term='mSev'))\n",
    "rays_duration =  StudyFactor(name = 'treatment duration', factor_type=OntologyAnnotation(term=\"time\"))\n",
    "rays_durationv = FactorValue(factor_name=rays_duration, value='30', unit=OntologyAnnotation(term='minutes'))\n",
    "te3.factor_values = [raysv,rays_intensityv,rays_durationv]\n",
    "print(te3)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creation of 'wash out' period as an `ISA Study Design Element`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen\n"
     ]
    }
   ],
   "source": [
    "# Creation of another ISA element, which is not a Treatment element, which is of type `screen` by default\n",
    "nte2 = NonTreatment(duration_unit=OntologyAnnotation(term=\"days\"))\n",
    "print(nte2.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-in\n"
     ]
    }
   ],
   "source": [
    "# let's change it by setting its type by relying on the keys defined for the object\n",
    "nte2.type=RUN_IN\n",
    "print(nte2.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washout\n"
     ]
    }
   ],
   "source": [
    "#let's change it again by direct use of the allowed strings (note: the string should match exactly the predefined values)\n",
    "nte2.type = WASHOUT\n",
    "print(nte2.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting the factor values associated with 'default' DURATION Factor associated with such elements\n",
    "nte2.duration.value=2\n",
    "nte2.duration.unit=OntologyAnnotation(term=\"weeks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creation of 'follow-up' period as an `ISA Study Design Element`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonTreatment(\n",
      "            type='follow-up',\n",
      "            duration=isatools.model.FactorValue(factor_name=isatools.model.StudyFactor(name='DURATION', factor_type=isatools.model.OntologyAnnotation(term='time', term_source=None, term_accession='', comments=[]), comments=[]), value=4, unit=isatools.model.OntologyAnnotation(term='month', term_source=None, term_accession='', comments=[]))\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "nte3 = NonTreatment(element_type=FOLLOW_UP, duration_value=4, duration_unit=OntologyAnnotation(term=\"month\"))\n",
    "# nte3.duration.value = 2\n",
    "# nte3.duration.unit = 'months'\n",
    "print(nte3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Creation of the associated container, known as an ISA `Cell` for each ISA `Element`.\n",
    "In this example, a single `Element` is hosted by a `Cell`, which must be named. In more complex designs (e.g. study designs with assymetric arms), a `Cell` may contain more than one `Element`, hence the list attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_cl1= StudyCell(name=\"st_cl1\", elements=[nte1])\n",
    "st_cl2= StudyCell(name=\"st_cl2\", elements=[te1])\n",
    "st_cl3= StudyCell(name=\"st_cl3\", elements=[nte2])\n",
    "st_cl4= StudyCell(name=\"st_cl4\", elements=[te2])\n",
    "st_cl6= StudyCell(name=\"st_cl6\", elements=[nte2])\n",
    "st_cl7= StudyCell(name=\"st_cl7\", elements=[te3])\n",
    "st_cl5= StudyCell(name=\"st_cl5\", elements=[nte3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Creation of an ISA `Study Arm` and setting the number of subjects associated to that unique sequence of ISA `Cell`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"StudyArm(\n",
      "               name=Arm 1,\n",
      "               source_type=Characteristic(\n",
      "    category=Study Subject\n",
      "    value=Human\n",
      "    unit=\n",
      "    comments=0 Comment objects\n",
      "),\n",
      "               group_size=5, \n",
      "               no. cells=0,\n",
      "               no. sample_assay_plans=0\n",
      "               )\n",
      "\"StudyArm(\n",
      "               name=Arm 1,\n",
      "               source_type=Characteristic(\n",
      "    category=genotype\n",
      "    value=control - normal\n",
      "    unit=\n",
      "    comments=0 Comment objects\n",
      "),\n",
      "               group_size=2, \n",
      "               no. cells=0,\n",
      "               no. sample_assay_plans=0\n",
      "               )\n"
     ]
    }
   ],
   "source": [
    "arm1 = StudyArm(name='Arm 1', group_size=5, )\n",
    "print(arm1)\n",
    "\n",
    "genotype_cat = OntologyAnnotation(term=\"genotype\")\n",
    "genotype_value1 = OntologyAnnotation(term=\"control - normal\")\n",
    "genotype_value2 = OntologyAnnotation(term=\"mutant\")\n",
    "\n",
    "arm1 = StudyArm(\n",
    "    name='Arm 1', \n",
    "    group_size=2, \n",
    "    source_type=Characteristic(\n",
    "        category=genotype_cat,\n",
    "        value=genotype_value1\n",
    "    )\n",
    ")\n",
    "print(arm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Declaring an ISA `Sample Assay Plan`, defining which `Sample` are to be collected and which `Assay`s to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_material1=ProductNode(id_=\"MAT1\", name=\"liver\", node_type=SAMPLE,size=1,characteristics=[Characteristic(category=OntologyAnnotation(term='organism part'), value=OntologyAnnotation(term='liver'))])\n",
    "input_material2=ProductNode(id_=\"MAT2\", name=\"blood\", node_type=SAMPLE,size=1,characteristics=[Characteristic(category=OntologyAnnotation(term='organism part'), value=OntologyAnnotation(term='blood'))])\n",
    "input_material3=ProductNode(id_=\"MAT3\", name=\"urine\", node_type=SAMPLE,size=3,characteristics=[Characteristic(category=OntologyAnnotation(term='organism part'), value=OntologyAnnotation(term='urine'))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Loading an isa assay definition in the form of an ordered dictionary. \n",
    "\n",
    "- It corresponds to an ISA configuration assay table but expressed in JSON.\n",
    "\n",
    "- In this NMR assay there is a sample extraction step, which produces \"supernatant\" and \"pellet\" extracts (1 of each per input sample).\n",
    "\n",
    "- IMPORTANT: Note how ISA `OntologyAnnotation` elements are used in this data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmr_assay_dict = OrderedDict([\n",
    "    ('measurement_type', OntologyAnnotation(term='metabolite profiling')),\n",
    "    ('technology_type', OntologyAnnotation(term='nmr spectroscopy')),\n",
    "            ('extraction', {}),\n",
    "            ('extract', [\n",
    "                {\n",
    "                    'node_type': EXTRACT,\n",
    "                    'characteristics_category': OntologyAnnotation(term='extract type'),\n",
    "                    'characteristics_value': 'supernatant',\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': None,\n",
    "                    'is_input_to_next_protocols': True\n",
    "                },\n",
    "                {\n",
    "                    'node_type': EXTRACT,\n",
    "                    'characteristics_category': OntologyAnnotation(term='extract type'),\n",
    "                    'characteristics_value': 'pellet',\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': None,\n",
    "                    'is_input_to_next_protocols': True\n",
    "                }\n",
    "            ]),\n",
    "            ('nmr_spectroscopy', {\n",
    "                OntologyAnnotation(term='instrument'): ['Bruker AvanceII 1 GHz'],\n",
    "                OntologyAnnotation(term='acquisition_mode'): ['1D 13C NMR','1D 1H NMR','2D 13C-13C NMR'],\n",
    "                OntologyAnnotation(term='pulse_sequence'): ['CPMG','TOCSY','HOESY','watergate']\n",
    "            }),\n",
    "            ('raw_spectral_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 2,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. We now show how to create an new AssayGraph structure from scratch, as if we were defining a completely new assay type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_assay_graph1=AssayGraph(\n",
    "    id_=\"WB\",\n",
    "    measurement_type=OntologyAnnotation(term=\"protein profiling\"),\n",
    "    technology_type=OntologyAnnotation(term=\"Western blot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. We procede by assembling the Process graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "protocol_node_protein = ProtocolNode(id_=\"P\",name='Protein extraction')\n",
    "protocol_node_data_acq = ProtocolNode(\n",
    "    id_=\"DA\",\n",
    "    name='WB imaging',\n",
    "    parameter_values=[\n",
    "        ParameterValue(\n",
    "            category=ProtocolParameter(parameter_name=OntologyAnnotation(term=\"channel\")),\n",
    "            value=OntologyAnnotation(term=\"360 nm\")\n",
    "        ),\n",
    "        ParameterValue(\n",
    "            category=ProtocolParameter(parameter_name=OntologyAnnotation(term='channel')),\n",
    "            value=OntologyAnnotation(term=\"550 nm\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "protein_char = Characteristic(category=OntologyAnnotation(term='material type'), value='protein extract')\n",
    "protein_sample_node = ProductNode(id_=\"SP\", node_type=EXTRACT, size=1, characteristics=[protein_char])\n",
    "wb_data_node = ProductNode(id_=\"WBD\", node_type=DATA_FILE, size=1)\n",
    "\n",
    "\n",
    "nodes = [protein_sample_node, wb_data_node, protocol_node_protein, protocol_node_data_acq]\n",
    "links = [\n",
    "    (protocol_node_protein, protein_sample_node),\n",
    "    (protein_sample_node, protocol_node_data_acq),\n",
    "    (protocol_node_data_acq, wb_data_node)\n",
    "]\n",
    "\n",
    "new_assay_graph1.add_nodes(nodes)\n",
    "new_assay_graph1.add_links(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step does 3 things:\n",
    "\n",
    "- generate an assay plan from the assay declaration data strucure\n",
    "- create a `Sample and Assay Plan` object holding a list of samples and the list of assay workflows which have been declared\n",
    "- create a `Sample to Assay` object, which details which sample will be input to a specific assay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmr_assay_graph = AssayGraph.generate_assay_plan_from_dict(nmr_assay_dict)\n",
    "\n",
    "sap1 = SampleAndAssayPlan(\n",
    "    name='sap1',\n",
    "    sample_plan=[input_material1,input_material2,input_material3],\n",
    "    assay_plan=[new_assay_graph1,nmr_assay_graph]\n",
    ")\n",
    "\n",
    "sample2assay_plan = {\n",
    "    input_material3: [new_assay_graph1, nmr_assay_graph],\n",
    "    input_material2: [nmr_assay_graph],\n",
    "    input_material1: [nmr_assay_graph]\n",
    "}\n",
    "\n",
    "sap1.sample_to_assay_map = sample2assay_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specifying which sample type (sometimes referred to as specimen)\n",
    "# sap1.add_sample_type('liver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specifying how many times each specimen is supposed to be collected\n",
    "# sap1.add_sample_plan_record('liver',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### 9. Declaration of an ISA assay and linking specimen type and data acquisition plan for this assay\n",
    "# # declare the type of `Assay` which will be performed\n",
    "# assay_type1 = Assay(measurement_type='metabolite profiling', technology_type='mass spectrometry')\n",
    "# # associate this assay type to the `SampleAssayPlan`\n",
    "# sap1.add_assay_type(assay_type1)\n",
    "# # specify which `sample type` will be used as input to the declare `Assay`\n",
    "# sap1.add_assay_plan_record('liver',assay_type1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Build an ISA `Study Design Arm` by adding the first set of ISA `Cells` and setting the `Sample Assay Plan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arm 1 Characteristic(\n",
      "    category=genotype\n",
      "    value=control - normal\n",
      "    unit=\n",
      "    comments=0 Comment objects\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "arm1.add_item_to_arm_map(st_cl1,sap1)\n",
    "print(arm1.name, arm1.source_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 Now expanding the `Arm` by adding a new `Cell`, which uses the same `Sample Assay Plan` as the one used in Cell #1.\n",
    "Of course, the `Sample Assay Plan` for this new `Cell` could be different. It would have to be to built as shown before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm1.add_item_to_arm_map(st_cl2,sap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding the last section of the Arm, with a cell which also uses the same sample assay plan.\n",
    "arm1.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm1.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm1.add_item_to_arm_map(st_cl6,sap1)\n",
    "arm1.add_item_to_arm_map(st_cl7,sap1)\n",
    "arm1.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Creation of additional ISA Study Arms and setting the number of subjects associated to that unique sequence of ISA Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm2 = StudyArm(\n",
    "    name='Arm 2',\n",
    "    source_type=Characteristic(\n",
    "        category=genotype_cat,\n",
    "        value=genotype_value1\n",
    "    )\n",
    ")\n",
    "arm2.group_size=5\n",
    "arm2.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl2,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl6,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl7,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arm3 = StudyArm(\n",
    "    name='Arm 3',\n",
    "    source_type=Characteristic(\n",
    "        category=genotype_cat,\n",
    "        value=genotype_value1\n",
    "    )\n",
    ")\n",
    "arm3.group_size=5\n",
    "arm3.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl7,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl6,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl2,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl5,sap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. We can now create the ISA `Study Design` object, which will receive the `Arms` defined by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_design= StudyDesign(name='trial design #1')\n",
    "# print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a study arm to the study design object.\n",
    "study_design.add_study_arm(arm1)\n",
    "study_design.add_study_arm(arm2)\n",
    "study_design.add_study_arm(arm3)\n",
    "# print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's now serialize the ISA study design to JSON\n",
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "from isatools.create.model import StudyDesignEncoder\n",
    "\n",
    "f=json.dumps(study_design, cls=StudyDesignEncoder, sort_keys=True, indent=4, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 15. let's produce a graphical overview of the study design arms and the associated sample assay plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_treatment_factors(some_element):\n",
    "    treat = \"\"\n",
    "    for j in range(len(some_element['factorValues'])):\n",
    "        if j < len(some_element['factorValues']) - 1:\n",
    "            if 'unit' in some_element['factorValues'][j].keys():\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \" \" \\\n",
    "                        + str(some_element['factorValues'][j]['unit']['term'].lower()) + \", \"\n",
    "            else:\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \",\"\n",
    "        else:\n",
    "            if 'unit' in some_element['factorValues'][j].keys():\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \" \" \\\n",
    "                        + str(some_element['factorValues'][j]['unit']['term'].lower())\n",
    "            else:\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value'])\n",
    "\n",
    "    return treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "design = json.loads(json.dumps(study_design, cls=StudyDesignEncoder, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "frames = []\n",
    "Items = []\n",
    "\n",
    "# defining a color pallet for the different element types:\n",
    "element_colors = {\"biological intervention\": \"rgb(253,232,37)\",\n",
    "                  \"radiological intervention\": \"rgb(53, 155, 8)\",\n",
    "                  \"dietary intervention\": \"rgb(53, 155, 8)\",\n",
    "                  \"chemical intervention\": \"rgb(69, 13, 83)\",\n",
    "                  \"washout\": \"rgb(45, 62, 120)\",\n",
    "                  \"screen\": \"rgb(33, 144, 140)\",\n",
    "                  \"run in\": \"rgb(43, 144, 180)\",\n",
    "                  \"follow-up\": \"rgb(88, 189, 94)\",\n",
    "                  \"concomitant treatment\": \"rgb(255, 255, 0)\"}\n",
    "\n",
    "# processing the study design arms and treatment plans:\n",
    "for key in design[\"studyArms\"].keys():\n",
    "    DF = pd.DataFrame(columns=['Arm', 'Cell', 'Type', 'Start_date', 'End_date', 'Treatment', 'Color'])\n",
    "    arm_name = key\n",
    "    # print(\"arm: \", arm_name)\n",
    "    size = design[\"studyArms\"][key][\"groupSize\"]\n",
    "    size_annotation = \"n=\" + str(size)\n",
    "\n",
    "    cells_per_arm = design[\"studyArms\"][key][\"cells\"]\n",
    "    cell_counter = 0\n",
    "    for cell in cells_per_arm:\n",
    "        cell_name = cell['name']\n",
    "        elements_per_cell = cell['elements']\n",
    "\n",
    "        for element in elements_per_cell:\n",
    "            treat = \"\"\n",
    "            element_counter = 0                      \n",
    "            if 'concomitantTreatments' in element.keys():\n",
    "                element_counter = element_counter + 1\n",
    "                treatments = []\n",
    "                for item in element['concomitantTreatments']:\n",
    "                    treatment = get_treatment_factors(item)\n",
    "                    treatments.append(treatment)\n",
    "                    \n",
    "                concomitant = ','.join(treatments[0:-1])\n",
    "                concomitant = concomitant + ' and ' + treatments[-1]\n",
    "                array = [arm_name, cell_name, arm_name + \": [\" + concomitant + \"]_concomitant_\" + str(cell_counter),\n",
    "                     dt.datetime(cell_counter + 2000, 1, 1), dt.datetime(cell_counter + 2000 + 1, 1, 1),\n",
    "                     str(element['factorValues']),\n",
    "                     concomitant,\n",
    "                     element_colors[\"concomitant treatment\"]]\n",
    "                Items.append(array)\n",
    "\n",
    "            elif 'type' in element.keys():\n",
    "                treatment = get_treatment_factors(element)\n",
    "                element_counter = element_counter + 1\n",
    "                array = [arm_name, cell_name, arm_name + \": [\" + str(element['type']) + \"]_\" + str(cell_counter),\n",
    "                         dt.datetime((cell_counter + 2000), 1, 1), dt.datetime((cell_counter + 2000 + 1), 1, 1),\n",
    "                         # str(element['factorValues']),\n",
    "                         str(treatment),\n",
    "                         element_colors[element['type']]]\n",
    "                Items.append(array)\n",
    "\n",
    "            cell_counter = cell_counter + 1\n",
    "\n",
    "for i, Dat in enumerate(Items):\n",
    "    DF.loc[i] = Dat\n",
    "#     print(\"setting:\", DF.loc[i])\n",
    "\n",
    "# providing the canvas for the figure\n",
    "# print(\"THESE ARE THE TYPES_: \", DF.Type.tolist())\n",
    "fig = figure(title='Study Design Treatment Plan',\n",
    "             width=800,\n",
    "             height=400,\n",
    "             y_range=DF.Type.tolist(),\n",
    "             x_range=Range1d(DF.Start_date.min(), DF.End_date.max()),\n",
    "             tools='save')\n",
    "\n",
    "# adding a tool tip\n",
    "hover = HoverTool(tooltips=\"Task: @Type<br>\\\n",
    "Start: @Start_date<br>\\\n",
    "Cell_Name: @Cell<br>\\\n",
    "Treatment: @Treatment\")\n",
    "fig.add_tools(hover)\n",
    "\n",
    "DF['ID'] = DF.index+0.8\n",
    "# print(\"ID: \", DF['ID'])\n",
    "DF['ID1'] = DF.index+1.2\n",
    "# print(\"ID1: \", DF['ID1'])\n",
    "CDS = ColumnDataSource(DF)\n",
    "# , legend=str(size_annotation)\n",
    "r = fig.quad(left='Start_date', right='End_date', bottom='ID', top='ID1', source=CDS, color=\"Color\")\n",
    "fig.xaxis.axis_label = 'Time'\n",
    "fig.yaxis.axis_label = 'study arms'\n",
    "\n",
    "# working at providing a background color change for every arm in the study design\n",
    "counts = DF['Arm'].value_counts().tolist()\n",
    "# print(\"total number of study arms:\", len(counts), \"| number of phases per arm:\", counts)\n",
    "# box = []\n",
    "# for i, this_element in enumerate(DF['Arm']):\n",
    "#     if i==0:\n",
    "#         box[i] = BoxAnnotation(bottom=0,\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              fill_color=\"blue\")\n",
    "#     elif i % 2 == 0:\n",
    "#         box[i] = BoxAnnotation(bottom=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              fill_color=\"silver\")\n",
    "#     else:\n",
    "#         box[i] = BoxAnnotation(bottom=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0] + DF['Arm'].value_counts().tolist()[1],\n",
    "#                              fill_color=\"grey\",\n",
    "#                              fill_alpha=0.1)\n",
    "# # adding the background color for each arm:\n",
    "# for element in box:\n",
    "#     fig.add_layout(element)\n",
    "# # fig.add_layout(box2)\n",
    "# # fig.add_layout(legend,'right')\n",
    "\n",
    "caption1 = Legend(items=[(str(size_annotation), [r])])\n",
    "fig.add_layout(caption1, 'right')\n",
    "\n",
    "citation = Label(x=10, y=-80, x_units='screen', y_units='screen',\n",
    "                 text='repeated measure group design layout - isa-api 0.12', render_mode='css',\n",
    "                 border_line_color='gray', border_line_alpha=0.4,\n",
    "                 background_fill_color='white', background_fill_alpha=1.0)\n",
    "\n",
    "fig.add_layout(citation)\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This statement will take some time to execute. Be patients\n",
    "study = study_design.generate_isa_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(study.assays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigation.studies=[study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay(\n",
      "    measurement_type=protein profiling\n",
      "    technology_type=Western blot\n",
      "    technology_platform=\n",
      "    filename=a_WB_protein-profiling_Western-blot.txt\n",
      "    data_files=252 DataFile objects\n",
      "    samples=0 Sample objects\n",
      "    process_sequence=504 Process objects\n",
      "    other_material=252 Material objects\n",
      "    characteristic_categories=0 OntologyAnnots\n",
      "    comments=0 Comment objects\n",
      "    units=0 Unit objects\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print(investigation.studies[0].assays[1])\n",
    "print(investigation.studies[0].assays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITING ISA-JSON document to string\n",
    "isa_json = json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 18:16:26,476 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [0, 1, 2]\n",
      "2021-07-21 18:16:26,735 [WARNING]: isatab.py(write_study_table_files:1195) >> [4, 3, 0, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15, 18, 17, 20, 19, 22, 21, 24, 23, 26, 25, 28, 27, 30, 29, 32, 31, 34, 33, 36, 35, 38, 37, 40, 39, 42, 41, 44, 43, 46, 45, 48, 47, 50, 49, 52, 51, 54, 53, 56, 55, 58, 57, 60, 59, 62, 61, 64, 63, 66, 65, 68, 67, 70, 69, 72, 71, 74, 73, 76, 75, 78, 77, 80, 79, 82, 81, 84, 83, 86, 85, 88, 87, 90, 89, 92, 91, 94, 93, 96, 95, 98, 97, 100, 99, 102, 101, 104, 103, 106, 105, 108, 107, 110, 109, 112, 111, 114, 113, 116, 115, 118, 117, 120, 119, 122, 121, 124, 123, 126, 125, 128, 127, 130, 129, 132, 131, 134, 133, 136, 135, 138, 137, 140, 139, 142, 141, 144, 143, 1, 146, 145, 148, 147, 150, 149, 152, 151, 154, 153, 156, 155, 158, 157, 160, 159, 162, 161, 164, 163, 166, 165, 168, 167, 170, 169, 172, 171, 174, 173, 176, 175, 178, 177, 180, 179, 182, 181, 184, 183, 186, 185, 188, 187, 190, 189, 192, 191, 194, 193, 196, 195, 198, 197, 200, 199, 202, 201, 204, 203, 206, 205, 208, 207, 210, 209, 212, 211, 214, 213, 216, 215, 218, 217, 220, 219, 222, 221, 224, 223, 226, 225, 228, 227, 230, 229, 232, 231, 234, 233, 236, 235, 238, 237, 240, 239, 242, 241, 244, 243, 246, 245, 248, 247, 250, 249, 252, 251, 254, 253, 256, 255, 258, 257, 260, 259, 262, 261, 264, 263, 266, 265, 268, 267, 270, 269, 272, 271, 274, 273, 276, 275, 278, 277, 280, 279, 282, 281, 284, 283, 286, 285, 288, 287, 290, 289, 292, 291, 294, 293, 296, 295, 298, 297, 300, 299, 302, 301, 304, 303, 306, 305, 308, 307, 310, 309, 312, 311, 314, 313, 316, 315, 318, 317, 320, 319, 322, 321, 324, 323, 326, 325, 328, 327, 330, 329, 332, 331, 334, 333, 336, 335, 338, 337, 340, 339, 342, 341, 344, 343, 346, 345, 348, 347, 350, 349, 352, 351, 354, 353, 356, 355, 358, 357, 360, 359, 362, 361, 364, 363, 366, 365, 368, 367, 370, 369, 372, 371, 374, 373, 376, 375, 378, 377, 380, 379, 382, 381, 384, 383, 386, 385, 388, 387, 390, 389, 392, 391, 394, 393, 396, 395, 398, 397, 400, 399, 402, 401, 404, 403, 406, 405, 408, 407, 410, 409, 412, 411, 414, 413, 416, 415, 418, 417, 420, 419, 422, 421, 424, 423, 426, 425, 428, 427, 430, 429, 432, 431, 434, 433, 436, 435, 438, 437, 440, 439, 442, 441, 444, 443, 446, 445, 448, 447, 450, 449, 452, 451, 454, 453, 456, 455, 458, 457, 460, 459, 462, 461, 464, 463, 466, 465, 468, 467, 470, 469, 472, 471, 474, 473, 476, 475, 478, 477, 480, 479, 482, 481, 484, 483, 486, 485, 488, 487, 490, 489, 492, 491, 494, 493, 2, 496, 495, 498, 497, 500, 499, 502, 501, 504, 503, 506, 505, 508, 507, 510, 509, 512, 511, 514, 513, 516, 515, 518, 517, 520, 519, 522, 521, 524, 523, 526, 525, 528, 527, 530, 529, 532, 531, 534, 533, 536, 535, 538, 537, 540, 539, 542, 541, 544, 543, 546, 545, 548, 547, 550, 549, 552, 551, 554, 553, 556, 555, 558, 557, 560, 559, 562, 561, 564, 563, 566, 565, 568, 567, 570, 569, 572, 571, 574, 573, 576, 575, 578, 577, 580, 579, 582, 581, 584, 583, 586, 585, 588, 587, 590, 589, 592, 591, 594, 593, 596, 595, 598, 597, 600, 599, 602, 601, 604, 603, 606, 605, 608, 607, 610, 609, 612, 611, 614, 613, 616, 615, 618, 617, 620, 619, 622, 621, 624, 623, 626, 625, 628, 627, 630, 629, 632, 631, 634, 633, 636, 635, 638, 637, 640, 639, 642, 641, 644, 643, 646, 645, 648, 647, 650, 649, 652, 651, 654, 653, 656, 655, 658, 657, 660, 659, 662, 661, 664, 663, 666, 665, 668, 667, 670, 669, 672, 671, 674, 673, 676, 675, 678, 677, 680, 679, 682, 681, 684, 683, 686, 685, 688, 687, 690, 689, 692, 691, 694, 693, 696, 695, 698, 697, 700, 699, 702, 701, 704, 703, 706, 705, 708, 707, 710, 709, 712, 711, 714, 713, 716, 715, 718, 717, 720, 719, 722, 721, 724, 723, 726, 725, 728, 727, 730, 729, 732, 731, 734, 733, 736, 735, 738, 737, 740, 739, 742, 741, 744, 743, 746, 745, 748, 747, 750, 749, 752, 751, 754, 753, 756, 755, 758, 757, 760, 759, 762, 761, 764, 763, 766, 765, 768, 767, 770, 769, 772, 771, 774, 773, 776, 775, 778, 777, 780, 779, 782, 781, 784, 783, 786, 785, 788, 787, 790, 789, 792, 791, 794, 793, 796, 795, 798, 797, 800, 799, 802, 801, 804, 803, 806, 805, 808, 807, 810, 809, 812, 811, 814, 813, 816, 815, 818, 817, 820, 819, 822, 821, 824, 823, 826, 825, 828, 827, 830, 829, 832, 831, 834, 833, 836, 835, 838, 837, 840, 839, 842, 841]\n",
      "2021-07-21 18:16:26,736 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[0, 4, 3], [0, 6, 5], [0, 8, 7], [0, 10, 9], [0, 12, 11], [0, 14, 13], [0, 16, 15], [0, 18, 17], [0, 20, 19], [0, 22, 21], [0, 24, 23], [0, 26, 25], [0, 28, 27], [0, 30, 29], [0, 32, 31], [0, 34, 33], [0, 36, 35], [0, 38, 37], [0, 40, 39], [0, 42, 41], [0, 44, 43], [0, 46, 45], [0, 48, 47], [0, 50, 49], [0, 52, 51], [0, 54, 53], [0, 56, 55], [0, 58, 57], [0, 60, 59], [0, 62, 61], [0, 64, 63], [0, 66, 65], [0, 68, 67], [0, 70, 69], [0, 72, 71], [0, 74, 73], [0, 76, 75], [0, 78, 77], [0, 80, 79], [0, 82, 81], [0, 84, 83], [0, 86, 85], [0, 88, 87], [0, 90, 89], [0, 92, 91], [0, 94, 93], [0, 96, 95], [0, 98, 97], [0, 100, 99], [0, 102, 101], [0, 104, 103], [0, 106, 105], [0, 108, 107], [0, 110, 109], [0, 112, 111], [0, 114, 113], [0, 116, 115], [0, 118, 117], [0, 120, 119], [0, 122, 121], [0, 124, 123], [0, 126, 125], [0, 128, 127], [0, 130, 129], [0, 132, 131], [0, 134, 133], [0, 136, 135], [0, 138, 137], [0, 140, 139], [0, 142, 141], [1, 144, 143], [1, 146, 145], [1, 148, 147], [1, 150, 149], [1, 152, 151], [1, 154, 153], [1, 156, 155], [1, 158, 157], [1, 160, 159], [1, 162, 161], [1, 164, 163], [1, 166, 165], [1, 168, 167], [1, 170, 169], [1, 172, 171], [1, 174, 173], [1, 176, 175], [1, 178, 177], [1, 180, 179], [1, 182, 181], [1, 184, 183], [1, 186, 185], [1, 188, 187], [1, 190, 189], [1, 192, 191], [1, 194, 193], [1, 196, 195], [1, 198, 197], [1, 200, 199], [1, 202, 201], [1, 204, 203], [1, 206, 205], [1, 208, 207], [1, 210, 209], [1, 212, 211], [1, 214, 213], [1, 216, 215], [1, 218, 217], [1, 220, 219], [1, 222, 221], [1, 224, 223], [1, 226, 225], [1, 228, 227], [1, 230, 229], [1, 232, 231], [1, 234, 233], [1, 236, 235], [1, 238, 237], [1, 240, 239], [1, 242, 241], [1, 244, 243], [1, 246, 245], [1, 248, 247], [1, 250, 249], [1, 252, 251], [1, 254, 253], [1, 256, 255], [1, 258, 257], [1, 260, 259], [1, 262, 261], [1, 264, 263], [1, 266, 265], [1, 268, 267], [1, 270, 269], [1, 272, 271], [1, 274, 273], [1, 276, 275], [1, 278, 277], [1, 280, 279], [1, 282, 281], [1, 284, 283], [1, 286, 285], [1, 288, 287], [1, 290, 289], [1, 292, 291], [1, 294, 293], [1, 296, 295], [1, 298, 297], [1, 300, 299], [1, 302, 301], [1, 304, 303], [1, 306, 305], [1, 308, 307], [1, 310, 309], [1, 312, 311], [1, 314, 313], [1, 316, 315], [1, 318, 317], [1, 320, 319], [1, 322, 321], [1, 324, 323], [1, 326, 325], [1, 328, 327], [1, 330, 329], [1, 332, 331], [1, 334, 333], [1, 336, 335], [1, 338, 337], [1, 340, 339], [1, 342, 341], [1, 344, 343], [1, 346, 345], [1, 348, 347], [1, 350, 349], [1, 352, 351], [1, 354, 353], [1, 356, 355], [1, 358, 357], [1, 360, 359], [1, 362, 361], [1, 364, 363], [1, 366, 365], [1, 368, 367], [1, 370, 369], [1, 372, 371], [1, 374, 373], [1, 376, 375], [1, 378, 377], [1, 380, 379], [1, 382, 381], [1, 384, 383], [1, 386, 385], [1, 388, 387], [1, 390, 389], [1, 392, 391], [1, 394, 393], [1, 396, 395], [1, 398, 397], [1, 400, 399], [1, 402, 401], [1, 404, 403], [1, 406, 405], [1, 408, 407], [1, 410, 409], [1, 412, 411], [1, 414, 413], [1, 416, 415], [1, 418, 417], [1, 420, 419], [1, 422, 421], [1, 424, 423], [1, 426, 425], [1, 428, 427], [1, 430, 429], [1, 432, 431], [1, 434, 433], [1, 436, 435], [1, 438, 437], [1, 440, 439], [1, 442, 441], [1, 444, 443], [1, 446, 445], [1, 448, 447], [1, 450, 449], [1, 452, 451], [1, 454, 453], [1, 456, 455], [1, 458, 457], [1, 460, 459], [1, 462, 461], [1, 464, 463], [1, 466, 465], [1, 468, 467], [1, 470, 469], [1, 472, 471], [1, 474, 473], [1, 476, 475], [1, 478, 477], [1, 480, 479], [1, 482, 481], [1, 484, 483], [1, 486, 485], [1, 488, 487], [1, 490, 489], [1, 492, 491], [2, 494, 493], [2, 496, 495], [2, 498, 497], [2, 500, 499], [2, 502, 501], [2, 504, 503], [2, 506, 505], [2, 508, 507], [2, 510, 509], [2, 512, 511], [2, 514, 513], [2, 516, 515], [2, 518, 517], [2, 520, 519], [2, 522, 521], [2, 524, 523], [2, 526, 525], [2, 528, 527], [2, 530, 529], [2, 532, 531], [2, 534, 533], [2, 536, 535], [2, 538, 537], [2, 540, 539], [2, 542, 541], [2, 544, 543], [2, 546, 545], [2, 548, 547], [2, 550, 549], [2, 552, 551], [2, 554, 553], [2, 556, 555], [2, 558, 557], [2, 560, 559], [2, 562, 561], [2, 564, 563], [2, 566, 565], [2, 568, 567], [2, 570, 569], [2, 572, 571], [2, 574, 573], [2, 576, 575], [2, 578, 577], [2, 580, 579], [2, 582, 581], [2, 584, 583], [2, 586, 585], [2, 588, 587], [2, 590, 589], [2, 592, 591], [2, 594, 593], [2, 596, 595], [2, 598, 597], [2, 600, 599], [2, 602, 601], [2, 604, 603], [2, 606, 605], [2, 608, 607], [2, 610, 609], [2, 612, 611], [2, 614, 613], [2, 616, 615], [2, 618, 617], [2, 620, 619], [2, 622, 621], [2, 624, 623], [2, 626, 625], [2, 628, 627], [2, 630, 629], [2, 632, 631], [2, 634, 633], [2, 636, 635], [2, 638, 637], [2, 640, 639], [2, 642, 641], [2, 644, 643], [2, 646, 645], [2, 648, 647], [2, 650, 649], [2, 652, 651], [2, 654, 653], [2, 656, 655], [2, 658, 657], [2, 660, 659], [2, 662, 661], [2, 664, 663], [2, 666, 665], [2, 668, 667], [2, 670, 669], [2, 672, 671], [2, 674, 673], [2, 676, 675], [2, 678, 677], [2, 680, 679], [2, 682, 681], [2, 684, 683], [2, 686, 685], [2, 688, 687], [2, 690, 689], [2, 692, 691], [2, 694, 693], [2, 696, 695], [2, 698, 697], [2, 700, 699], [2, 702, 701], [2, 704, 703], [2, 706, 705], [2, 708, 707], [2, 710, 709], [2, 712, 711], [2, 714, 713], [2, 716, 715], [2, 718, 717], [2, 720, 719], [2, 722, 721], [2, 724, 723], [2, 726, 725], [2, 728, 727], [2, 730, 729], [2, 732, 731], [2, 734, 733], [2, 736, 735], [2, 738, 737], [2, 740, 739], [2, 742, 741], [2, 744, 743], [2, 746, 745], [2, 748, 747], [2, 750, 749], [2, 752, 751], [2, 754, 753], [2, 756, 755], [2, 758, 757], [2, 760, 759], [2, 762, 761], [2, 764, 763], [2, 766, 765], [2, 768, 767], [2, 770, 769], [2, 772, 771], [2, 774, 773], [2, 776, 775], [2, 778, 777], [2, 780, 779], [2, 782, 781], [2, 784, 783], [2, 786, 785], [2, 788, 787], [2, 790, 789], [2, 792, 791], [2, 794, 793], [2, 796, 795], [2, 798, 797], [2, 800, 799], [2, 802, 801], [2, 804, 803], [2, 806, 805], [2, 808, 807], [2, 810, 809], [2, 812, 811], [2, 814, 813], [2, 816, 815], [2, 818, 817], [2, 820, 819], [2, 822, 821], [2, 824, 823], [2, 826, 825], [2, 828, 827], [2, 830, 829], [2, 832, 831], [2, 834, 833], [2, 836, 835], [2, 838, 837], [2, 840, 839], [2, 842, 841]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sample Name.0.Factor Value[DURATION]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/rl6lqnks4rqb59pbtpvvntqw0000gr/T/ipykernel_18651/1244306393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0misatools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misatab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_tables_to_dataframes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdumpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mdump_tables_to_dataframes\u001b[0;34m(isa_obj)\u001b[0m\n\u001b[1;32m   4578\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4579\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4580\u001b[0;31m         \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misa_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misa_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_dump_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4581\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's_*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_tfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(isa_obj, output_path, i_file_name, skip_dump_tables, write_factor_values_in_assay_table)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mwrite_study_table_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         write_assay_table_files(\n\u001b[1;32m   1051\u001b[0m             investigation, output_path, write_factor_values_in_assay_table)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_study_table_files\u001b[0;34m(inv_obj, output_dir)\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         fvlabel = \"{0}.Factor Value[{1}]\".format(\n\u001b[1;32m   1297\u001b[0m                             olabel, fv.factor_name.name)\n\u001b[0;32m-> 1298\u001b[0;31m                         \u001b[0mwrite_value_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m         \"\"\"if isinstance(pbar, ProgressBar):\n\u001b[1;32m   1300\u001b[0m             pbar.finish()\"\"\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_value_columns\u001b[0;34m(df_dict, label, x)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOntologyAnnotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit.Term Source REF\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sample Name.0.Factor Value[DURATION]'"
     ]
    }
   ],
   "source": [
    "# from isatools.isatab import dump_tables_to_dataframes as dumpdf\n",
    "# dataframes = dumpdf(investigation)\n",
    "# dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-09 18:51:57,184 [INFO]: isatab.py(_all_end_to_end_paths:1131) >> [0, 1, 2]\n",
      "2021-08-09 18:51:57,468 [WARNING]: isatab.py(write_study_table_files:1194) >> [4, 3, 0, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15, 18, 17, 20, 19, 22, 21, 24, 23, 26, 25, 28, 27, 30, 29, 32, 31, 34, 33, 36, 35, 38, 37, 40, 39, 42, 41, 44, 43, 46, 45, 48, 47, 50, 49, 52, 51, 54, 53, 56, 55, 58, 57, 60, 59, 62, 61, 64, 63, 66, 65, 68, 67, 70, 69, 72, 71, 74, 73, 76, 75, 78, 77, 80, 79, 82, 81, 84, 83, 86, 85, 88, 87, 90, 89, 92, 91, 94, 93, 96, 95, 98, 97, 100, 99, 102, 101, 104, 103, 106, 105, 108, 107, 110, 109, 112, 111, 114, 113, 116, 115, 118, 117, 120, 119, 122, 121, 124, 123, 126, 125, 128, 127, 130, 129, 132, 131, 134, 133, 136, 135, 138, 137, 140, 139, 142, 141, 144, 143, 1, 146, 145, 148, 147, 150, 149, 152, 151, 154, 153, 156, 155, 158, 157, 160, 159, 162, 161, 164, 163, 166, 165, 168, 167, 170, 169, 172, 171, 174, 173, 176, 175, 178, 177, 180, 179, 182, 181, 184, 183, 186, 185, 188, 187, 190, 189, 192, 191, 194, 193, 196, 195, 198, 197, 200, 199, 202, 201, 204, 203, 206, 205, 208, 207, 210, 209, 212, 211, 214, 213, 216, 215, 218, 217, 220, 219, 222, 221, 224, 223, 226, 225, 228, 227, 230, 229, 232, 231, 234, 233, 236, 235, 238, 237, 240, 239, 242, 241, 244, 243, 246, 245, 248, 247, 250, 249, 252, 251, 254, 253, 256, 255, 258, 257, 260, 259, 262, 261, 264, 263, 266, 265, 268, 267, 270, 269, 272, 271, 274, 273, 276, 275, 278, 277, 280, 279, 282, 281, 284, 283, 286, 285, 288, 287, 290, 289, 292, 291, 294, 293, 296, 295, 298, 297, 300, 299, 302, 301, 304, 303, 306, 305, 308, 307, 310, 309, 312, 311, 314, 313, 316, 315, 318, 317, 320, 319, 322, 321, 324, 323, 326, 325, 328, 327, 330, 329, 332, 331, 334, 333, 336, 335, 338, 337, 340, 339, 342, 341, 344, 343, 346, 345, 348, 347, 350, 349, 352, 351, 354, 353, 356, 355, 358, 357, 360, 359, 362, 361, 364, 363, 366, 365, 368, 367, 370, 369, 372, 371, 374, 373, 376, 375, 378, 377, 380, 379, 382, 381, 384, 383, 386, 385, 388, 387, 390, 389, 392, 391, 394, 393, 396, 395, 398, 397, 400, 399, 402, 401, 404, 403, 406, 405, 408, 407, 410, 409, 412, 411, 414, 413, 416, 415, 418, 417, 420, 419, 422, 421, 424, 423, 426, 425, 428, 427, 430, 429, 432, 431, 434, 433, 436, 435, 438, 437, 440, 439, 442, 441, 444, 443, 446, 445, 448, 447, 450, 449, 452, 451, 454, 453, 456, 455, 458, 457, 460, 459, 462, 461, 464, 463, 466, 465, 468, 467, 470, 469, 472, 471, 474, 473, 476, 475, 478, 477, 480, 479, 482, 481, 484, 483, 486, 485, 488, 487, 490, 489, 492, 491, 494, 493, 2, 496, 495, 498, 497, 500, 499, 502, 501, 504, 503, 506, 505, 508, 507, 510, 509, 512, 511, 514, 513, 516, 515, 518, 517, 520, 519, 522, 521, 524, 523, 526, 525, 528, 527, 530, 529, 532, 531, 534, 533, 536, 535, 538, 537, 540, 539, 542, 541, 544, 543, 546, 545, 548, 547, 550, 549, 552, 551, 554, 553, 556, 555, 558, 557, 560, 559, 562, 561, 564, 563, 566, 565, 568, 567, 570, 569, 572, 571, 574, 573, 576, 575, 578, 577, 580, 579, 582, 581, 584, 583, 586, 585, 588, 587, 590, 589, 592, 591, 594, 593, 596, 595, 598, 597, 600, 599, 602, 601, 604, 603, 606, 605, 608, 607, 610, 609, 612, 611, 614, 613, 616, 615, 618, 617, 620, 619, 622, 621, 624, 623, 626, 625, 628, 627, 630, 629, 632, 631, 634, 633, 636, 635, 638, 637, 640, 639, 642, 641, 644, 643, 646, 645, 648, 647, 650, 649, 652, 651, 654, 653, 656, 655, 658, 657, 660, 659, 662, 661, 664, 663, 666, 665, 668, 667, 670, 669, 672, 671, 674, 673, 676, 675, 678, 677, 680, 679, 682, 681, 684, 683, 686, 685, 688, 687, 690, 689, 692, 691, 694, 693, 696, 695, 698, 697, 700, 699, 702, 701, 704, 703, 706, 705, 708, 707, 710, 709, 712, 711, 714, 713, 716, 715, 718, 717, 720, 719, 722, 721, 724, 723, 726, 725, 728, 727, 730, 729, 732, 731, 734, 733, 736, 735, 738, 737, 740, 739, 742, 741, 744, 743, 746, 745, 748, 747, 750, 749, 752, 751, 754, 753, 756, 755, 758, 757, 760, 759, 762, 761, 764, 763, 766, 765, 768, 767, 770, 769, 772, 771, 774, 773, 776, 775, 778, 777, 780, 779, 782, 781, 784, 783, 786, 785, 788, 787, 790, 789, 792, 791, 794, 793, 796, 795, 798, 797, 800, 799, 802, 801, 804, 803, 806, 805, 808, 807, 810, 809, 812, 811, 814, 813, 816, 815, 818, 817, 820, 819, 822, 821, 824, 823, 826, 825, 828, 827, 830, 829, 832, 831, 834, 833, 836, 835, 838, 837, 840, 839, 842, 841]\n",
      "2021-08-09 18:51:57,471 [INFO]: isatab.py(_longest_path_and_attrs:1091) >> [[0, 4, 3], [0, 6, 5], [0, 8, 7], [0, 10, 9], [0, 12, 11], [0, 14, 13], [0, 16, 15], [0, 18, 17], [0, 20, 19], [0, 22, 21], [0, 24, 23], [0, 26, 25], [0, 28, 27], [0, 30, 29], [0, 32, 31], [0, 34, 33], [0, 36, 35], [0, 38, 37], [0, 40, 39], [0, 42, 41], [0, 44, 43], [0, 46, 45], [0, 48, 47], [0, 50, 49], [0, 52, 51], [0, 54, 53], [0, 56, 55], [0, 58, 57], [0, 60, 59], [0, 62, 61], [0, 64, 63], [0, 66, 65], [0, 68, 67], [0, 70, 69], [0, 72, 71], [0, 74, 73], [0, 76, 75], [0, 78, 77], [0, 80, 79], [0, 82, 81], [0, 84, 83], [0, 86, 85], [0, 88, 87], [0, 90, 89], [0, 92, 91], [0, 94, 93], [0, 96, 95], [0, 98, 97], [0, 100, 99], [0, 102, 101], [0, 104, 103], [0, 106, 105], [0, 108, 107], [0, 110, 109], [0, 112, 111], [0, 114, 113], [0, 116, 115], [0, 118, 117], [0, 120, 119], [0, 122, 121], [0, 124, 123], [0, 126, 125], [0, 128, 127], [0, 130, 129], [0, 132, 131], [0, 134, 133], [0, 136, 135], [0, 138, 137], [0, 140, 139], [0, 142, 141], [1, 144, 143], [1, 146, 145], [1, 148, 147], [1, 150, 149], [1, 152, 151], [1, 154, 153], [1, 156, 155], [1, 158, 157], [1, 160, 159], [1, 162, 161], [1, 164, 163], [1, 166, 165], [1, 168, 167], [1, 170, 169], [1, 172, 171], [1, 174, 173], [1, 176, 175], [1, 178, 177], [1, 180, 179], [1, 182, 181], [1, 184, 183], [1, 186, 185], [1, 188, 187], [1, 190, 189], [1, 192, 191], [1, 194, 193], [1, 196, 195], [1, 198, 197], [1, 200, 199], [1, 202, 201], [1, 204, 203], [1, 206, 205], [1, 208, 207], [1, 210, 209], [1, 212, 211], [1, 214, 213], [1, 216, 215], [1, 218, 217], [1, 220, 219], [1, 222, 221], [1, 224, 223], [1, 226, 225], [1, 228, 227], [1, 230, 229], [1, 232, 231], [1, 234, 233], [1, 236, 235], [1, 238, 237], [1, 240, 239], [1, 242, 241], [1, 244, 243], [1, 246, 245], [1, 248, 247], [1, 250, 249], [1, 252, 251], [1, 254, 253], [1, 256, 255], [1, 258, 257], [1, 260, 259], [1, 262, 261], [1, 264, 263], [1, 266, 265], [1, 268, 267], [1, 270, 269], [1, 272, 271], [1, 274, 273], [1, 276, 275], [1, 278, 277], [1, 280, 279], [1, 282, 281], [1, 284, 283], [1, 286, 285], [1, 288, 287], [1, 290, 289], [1, 292, 291], [1, 294, 293], [1, 296, 295], [1, 298, 297], [1, 300, 299], [1, 302, 301], [1, 304, 303], [1, 306, 305], [1, 308, 307], [1, 310, 309], [1, 312, 311], [1, 314, 313], [1, 316, 315], [1, 318, 317], [1, 320, 319], [1, 322, 321], [1, 324, 323], [1, 326, 325], [1, 328, 327], [1, 330, 329], [1, 332, 331], [1, 334, 333], [1, 336, 335], [1, 338, 337], [1, 340, 339], [1, 342, 341], [1, 344, 343], [1, 346, 345], [1, 348, 347], [1, 350, 349], [1, 352, 351], [1, 354, 353], [1, 356, 355], [1, 358, 357], [1, 360, 359], [1, 362, 361], [1, 364, 363], [1, 366, 365], [1, 368, 367], [1, 370, 369], [1, 372, 371], [1, 374, 373], [1, 376, 375], [1, 378, 377], [1, 380, 379], [1, 382, 381], [1, 384, 383], [1, 386, 385], [1, 388, 387], [1, 390, 389], [1, 392, 391], [1, 394, 393], [1, 396, 395], [1, 398, 397], [1, 400, 399], [1, 402, 401], [1, 404, 403], [1, 406, 405], [1, 408, 407], [1, 410, 409], [1, 412, 411], [1, 414, 413], [1, 416, 415], [1, 418, 417], [1, 420, 419], [1, 422, 421], [1, 424, 423], [1, 426, 425], [1, 428, 427], [1, 430, 429], [1, 432, 431], [1, 434, 433], [1, 436, 435], [1, 438, 437], [1, 440, 439], [1, 442, 441], [1, 444, 443], [1, 446, 445], [1, 448, 447], [1, 450, 449], [1, 452, 451], [1, 454, 453], [1, 456, 455], [1, 458, 457], [1, 460, 459], [1, 462, 461], [1, 464, 463], [1, 466, 465], [1, 468, 467], [1, 470, 469], [1, 472, 471], [1, 474, 473], [1, 476, 475], [1, 478, 477], [1, 480, 479], [1, 482, 481], [1, 484, 483], [1, 486, 485], [1, 488, 487], [1, 490, 489], [1, 492, 491], [2, 494, 493], [2, 496, 495], [2, 498, 497], [2, 500, 499], [2, 502, 501], [2, 504, 503], [2, 506, 505], [2, 508, 507], [2, 510, 509], [2, 512, 511], [2, 514, 513], [2, 516, 515], [2, 518, 517], [2, 520, 519], [2, 522, 521], [2, 524, 523], [2, 526, 525], [2, 528, 527], [2, 530, 529], [2, 532, 531], [2, 534, 533], [2, 536, 535], [2, 538, 537], [2, 540, 539], [2, 542, 541], [2, 544, 543], [2, 546, 545], [2, 548, 547], [2, 550, 549], [2, 552, 551], [2, 554, 553], [2, 556, 555], [2, 558, 557], [2, 560, 559], [2, 562, 561], [2, 564, 563], [2, 566, 565], [2, 568, 567], [2, 570, 569], [2, 572, 571], [2, 574, 573], [2, 576, 575], [2, 578, 577], [2, 580, 579], [2, 582, 581], [2, 584, 583], [2, 586, 585], [2, 588, 587], [2, 590, 589], [2, 592, 591], [2, 594, 593], [2, 596, 595], [2, 598, 597], [2, 600, 599], [2, 602, 601], [2, 604, 603], [2, 606, 605], [2, 608, 607], [2, 610, 609], [2, 612, 611], [2, 614, 613], [2, 616, 615], [2, 618, 617], [2, 620, 619], [2, 622, 621], [2, 624, 623], [2, 626, 625], [2, 628, 627], [2, 630, 629], [2, 632, 631], [2, 634, 633], [2, 636, 635], [2, 638, 637], [2, 640, 639], [2, 642, 641], [2, 644, 643], [2, 646, 645], [2, 648, 647], [2, 650, 649], [2, 652, 651], [2, 654, 653], [2, 656, 655], [2, 658, 657], [2, 660, 659], [2, 662, 661], [2, 664, 663], [2, 666, 665], [2, 668, 667], [2, 670, 669], [2, 672, 671], [2, 674, 673], [2, 676, 675], [2, 678, 677], [2, 680, 679], [2, 682, 681], [2, 684, 683], [2, 686, 685], [2, 688, 687], [2, 690, 689], [2, 692, 691], [2, 694, 693], [2, 696, 695], [2, 698, 697], [2, 700, 699], [2, 702, 701], [2, 704, 703], [2, 706, 705], [2, 708, 707], [2, 710, 709], [2, 712, 711], [2, 714, 713], [2, 716, 715], [2, 718, 717], [2, 720, 719], [2, 722, 721], [2, 724, 723], [2, 726, 725], [2, 728, 727], [2, 730, 729], [2, 732, 731], [2, 734, 733], [2, 736, 735], [2, 738, 737], [2, 740, 739], [2, 742, 741], [2, 744, 743], [2, 746, 745], [2, 748, 747], [2, 750, 749], [2, 752, 751], [2, 754, 753], [2, 756, 755], [2, 758, 757], [2, 760, 759], [2, 762, 761], [2, 764, 763], [2, 766, 765], [2, 768, 767], [2, 770, 769], [2, 772, 771], [2, 774, 773], [2, 776, 775], [2, 778, 777], [2, 780, 779], [2, 782, 781], [2, 784, 783], [2, 786, 785], [2, 788, 787], [2, 790, 789], [2, 792, 791], [2, 794, 793], [2, 796, 795], [2, 798, 797], [2, 800, 799], [2, 802, 801], [2, 804, 803], [2, 806, 805], [2, 808, 807], [2, 810, 809], [2, 812, 811], [2, 814, 813], [2, 816, 815], [2, 818, 817], [2, 820, 819], [2, 822, 821], [2, 824, 823], [2, 826, 825], [2, 828, 827], [2, 830, 829], [2, 832, 831], [2, 834, 833], [2, 836, 835], [2, 838, 837], [2, 840, 839], [2, 842, 841]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sample Name.0.Factor Value[DURATION]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/rl6lqnks4rqb59pbtpvvntqw0000gr/T/ipykernel_54507/4200718032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# os.makedirs('/notebook-output/isa-repeated-measure-crossover-design', exist_ok = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0misatab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./notebook-output/isa-repeated-measure-crossover-design'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(isa_obj, output_path, i_file_name, skip_dump_tables, write_factor_values_in_assay_table)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mwrite_study_table_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         write_assay_table_files(\n\u001b[1;32m   1051\u001b[0m             investigation, output_path, write_factor_values_in_assay_table)\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_study_table_files\u001b[0;34m(inv_obj, output_dir)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         fvlabel = \"{0}.Factor Value[{1}]\".format(\n\u001b[1;32m   1296\u001b[0m                             olabel, fv.factor_name.name)\n\u001b[0;32m-> 1297\u001b[0;31m                         \u001b[0mwrite_value_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m         \"\"\"if isinstance(pbar, ProgressBar):\n\u001b[1;32m   1299\u001b[0m             pbar.finish()\"\"\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/envs/isa-api-py39/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_value_columns\u001b[0;34m(df_dict, label, x)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOntologyAnnotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".Unit.Term Source REF\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sample Name.0.Factor Value[DURATION]'"
     ]
    }
   ],
   "source": [
    "# Alternatevely, if you want to save the ISA-TAB files to a specific directory, you can run:\n",
    "from isatools import isatab\n",
    "# import os\n",
    "# os.makedirs('/notebook-output/isa-repeated-measure-crossover-design', exist_ok = True)\n",
    "isatab.dump(investigation, './notebook-output/isa-repeated-measure-crossover-design')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[list(dataframes.keys())[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in study.assays[0].graph.nodes() if isinstance(x, Sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in study.assays[0].graph.nodes() if isinstance(x, Sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[getattr(x, 'name', None) for x in study.assays[0].graph.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "- authors: philippe.rocca-serra@oerc.ox.ac.uk, massimiliano.izzo@oerc.ox.ac.uk\n",
    "- license: CC-BY 4.0\n",
    "- support: isatools@googlegroups.com\n",
    "- issue tracker: https://github.com/ISA-tools/isa-api/issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py39",
   "language": "python",
   "name": "isa-api-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
