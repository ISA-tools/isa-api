{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an ISA Study representing a 2x2x2 factorial design with single measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "In this notebook, we'll show how a study design defines a series of interventions with two distinct radiological agents, at two distinct dose levels and 2 distinct timepoints of observation post-exposure.\n",
    "\n",
    "|Factor Name|Factor Type|Factor Value|Unit| Factor Value|Unit|Number of factor levels|\n",
    "|:---|:---|:---|:---:|:---|:---:|---:|\n",
    "|radionucleide|radiological agent|Cs 137| |Fe 56|| 2 |\n",
    "|dose|intensity | 2.5 | cGy | 10 | cGy | 2 |\n",
    "|time post exposure| time| 1 | hr | 72 | hr | 2 |\n",
    "\n",
    "In this experiment, *muscle* samples are collected once from each study subject (n=10 per group) and `metabolite profiling` using `1D 13C NMR` is performed on the `supernatant` and `pellet` of the extracted fraction.\n",
    "Subjects were also `phenotyped using a custom hyperspectral imaging`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get the toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If executing the notebooks on `Google Colab`,uncomment the following command \n",
    "# and run it to install the required python libraries. Also, make the test datasets available.\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from isatools.model import (\n",
    "    Investigation,\n",
    "    Study,\n",
    "    StudyFactor,\n",
    "    FactorValue, \n",
    "    OntologyAnnotation,\n",
    "    Sample,\n",
    "    Characteristic,\n",
    "    Protocol\n",
    ")\n",
    "\n",
    "from isatools.create.model import (\n",
    "    Treatment,\n",
    "    StudyCell,\n",
    "    StudyArm,\n",
    "    ProductNode,\n",
    "    AssayGraph,\n",
    "    SampleAndAssayPlan,\n",
    "    StudyDesign,\n",
    "    QualityControl\n",
    ")\n",
    "\n",
    "from isatools.create.constants import (\n",
    "    SAMPLE,\n",
    "    EXTRACT,\n",
    "    DATA_FILE\n",
    ")\n",
    "\n",
    "from isatools.isajson import ISAJSONEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the ISA Study core metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "investigation = Investigation()\n",
    "study = Study(filename=\"s_study_2by2by2.txt\")\n",
    "study.identifier = \"2x2x2\"\n",
    "study.title = \"2x2x2 factorial design study\"\n",
    "study.description = \"a simple full factorial design study 2x2x2\"\n",
    "study.submission_date = \"2021-04-21\" # Note the ISO8601 format for dates\n",
    "study.public_release_date = \"2021-05-30\"  # Note the ISO8601 format for dates\n",
    "study.protocols = [Protocol(name=\"sample collection\")]\n",
    "investigation.studies = [study]\n",
    "print(investigation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the ISA Study Design Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring the 3 independent variables (ISA Factors) of the Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1 = StudyFactor(name='radionucleide', factor_type=OntologyAnnotation(term=\"radiological agent\"))\n",
    "f2 = StudyFactor(name='dose', factor_type=OntologyAnnotation(term=\"intensity\"))\n",
    "f3 = StudyFactor(name='time post exposure', factor_type=OntologyAnnotation(term=\"time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring the treatment groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te1 = Treatment()\n",
    "te1.type='radiological intervention'\n",
    "\n",
    "f1v1 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Cs 137\"))\n",
    "f2v1 = FactorValue(factor_name=f2, value=2.5, unit=OntologyAnnotation(term='cGy'))\n",
    "f3v1 = FactorValue(factor_name=f3, value=1, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te1.factor_values = (f1v1,f2v1,f3v1)\n",
    "# te1.factor_values.add(f1v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te6 = Treatment()\n",
    "te6.type='radiological intervention'\n",
    "\n",
    "f1v1 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Cs 137\"))\n",
    "f2v1 = FactorValue(factor_name=f2, value=2.5,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v2 = FactorValue(factor_name=f3, value=72, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te6.factor_values = (f1v1,f2v1,f3v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te2 = Treatment()\n",
    "te2.type='radiological intervention'\n",
    "\n",
    "f1v1 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Cs 137\"))\n",
    "f2v2 = FactorValue(factor_name=f2, value=10,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v2 = FactorValue(factor_name=f3, value=72, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te2.factor_values = (f1v1,f2v2,f3v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te7 = Treatment()\n",
    "te7.type='radiological intervention'\n",
    "\n",
    "f1v2 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Cs 137\"))\n",
    "f2v1 = FactorValue(factor_name=f2, value=10,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v2 = FactorValue(factor_name=f3, value=72, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te7.factor_values = (f1v2,f2v1,f3v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te3 = Treatment()\n",
    "te3.type='radiological intervention'\n",
    "\n",
    "f1v2 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Fe 56\"))\n",
    "f2v1 = FactorValue(factor_name=f2, value=2.5,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v1 = FactorValue(factor_name=f3, value=1, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te3.factor_values = (f1v2,f2v1,f3v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te5 = Treatment()\n",
    "te5.type='radiological intervention'\n",
    "\n",
    "f1v2 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Fe 56\"))\n",
    "f2v1 = FactorValue(factor_name=f2, value=2.5,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v2 = FactorValue(factor_name=f3, value=72, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te5.factor_values = (f1v2,f2v1,f3v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te8 = Treatment()\n",
    "te8.type='radiological intervention'\n",
    "\n",
    "f1v2 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Fe 56\"))\n",
    "f2v2 = FactorValue(factor_name=f2, value=10,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v1 = FactorValue(factor_name=f3, value=1, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te8.factor_values = (f1v2,f2v2,f3v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "te4 = Treatment()\n",
    "te4.type='radiological intervention'\n",
    "\n",
    "f1v2 = FactorValue(factor_name=f1, value=OntologyAnnotation(term=\"Fe 56\"))\n",
    "f2v2 = FactorValue(factor_name=f2, value=10,unit=OntologyAnnotation(term='cGy'))\n",
    "f3v2 = FactorValue(factor_name=f3, value=72, unit=OntologyAnnotation(term='hr'))\n",
    "\n",
    "te4.factor_values = (f1v2,f2v2,f3v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now building the Study Arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_cl1= StudyCell(name=\"st_cl1\", elements=[te1])\n",
    "st_cl2= StudyCell(name=\"st_cl2\", elements=[te2])\n",
    "st_cl3= StudyCell(name=\"st_cl3\", elements=[te3])\n",
    "st_cl4= StudyCell(name=\"st_cl4\", elements=[te4])\n",
    "st_cl5= StudyCell(name=\"st_cl5\", elements=[te5])\n",
    "st_cl6= StudyCell(name=\"st_cl6\", elements=[te6])\n",
    "st_cl7= StudyCell(name=\"st_cl7\", elements=[te7])\n",
    "st_cl8= StudyCell(name=\"st_cl8\", elements=[te8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm1 = StudyArm(name='Group 1', group_size=10, source_type=Characteristic(category=OntologyAnnotation(term=\"Study Subject\"),value=OntologyAnnotation(term=\"Mus musculus\")))\n",
    "arm2 = StudyArm(name='Group 2', group_size=10)\n",
    "arm3 = StudyArm(name='Group 3', group_size=10)\n",
    "arm4 = StudyArm(name='Group 4', group_size=10)\n",
    "arm5 = StudyArm(name='Group 5', group_size=10)\n",
    "arm6 = StudyArm(name='Group 6', group_size=10)\n",
    "arm7 = StudyArm(name='Group 7', group_size=10)\n",
    "arm8 = StudyArm(name='Group 8', group_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_material1=ProductNode(id_=\"MAT1\", name=\"muscle tissue\", node_type=SAMPLE,size=1,characteristics=[Characteristic(category=OntologyAnnotation(term='organism part'), value=OntologyAnnotation(term='muscle'))])\n",
    "#input_material2=ProductNode(id_=\"MAT2\", name=\"blood\", node_type=SAMPLE,size=1,characteristics=[Characteristic(category='organism part', value='blood')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A new data structure for defining an assay workflow\n",
    "\n",
    "The following cells show 2 distinct assay workflows, which are consumed by the `ISAcreate module` of the ISA-API to drive to creation of ISA objects. In this notebook, we show how the data structure can be used to pass workflow settings.  Each `Protocol Node` can be used to specify the number of technical replicates and parameter settings for each data acquisition to be executed. Note how these values are `OntologyAnnotation` and therefore can be marked up with URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmr_assay_dict = OrderedDict([\n",
    "    ('measurement_type', OntologyAnnotation(term='metabolite profiling')),\n",
    "    ('technology_type', OntologyAnnotation(term='nmr spectroscopy')),\n",
    "            ('extraction', {}),\n",
    "            ('extract', [\n",
    "                {\n",
    "                    'node_type': EXTRACT,\n",
    "                    'characteristics_category':  OntologyAnnotation(term='extract type'),\n",
    "                    'characteristics_value': OntologyAnnotation(term='supernatant'),\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': None,\n",
    "                    'is_input_to_next_protocols': True\n",
    "                },\n",
    "                {\n",
    "                    'node_type': EXTRACT,\n",
    "                    'characteristics_category':  OntologyAnnotation(term='extract type'),\n",
    "                    'characteristics_value': OntologyAnnotation(term='pellet'),\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': None,\n",
    "                    'is_input_to_next_protocols': True\n",
    "                }\n",
    "            ]),\n",
    "            ('nmr_spectroscopy', {\n",
    "                OntologyAnnotation(term='instrument'): [OntologyAnnotation(term='Bruker AvanceII 1 GHz')],\n",
    "                OntologyAnnotation(term='acquisition_mode'): [OntologyAnnotation(term='1D 13C NMR')],\n",
    "                OntologyAnnotation(term='pulse_sequence'): [OntologyAnnotation(term='CPMG')]\n",
    "            }),\n",
    "            ('raw_spectral_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 2,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_nasa_lab_dict = OrderedDict([\n",
    "        ('measurement_type', OntologyAnnotation(term='phenotyping')),\n",
    "        ('technology_type', OntologyAnnotation(term='hyperspectral imaging')),\n",
    "                ('hyperspectral imaging', {\n",
    "                OntologyAnnotation(term='instrument'): [OntologyAnnotation(term='Hitachi ZBR-II')],\n",
    "                OntologyAnnotation(term='acquisition_mode'): [OntologyAnnotation(term='multimodal')],\n",
    "                OntologyAnnotation(term='wavelength'): [OntologyAnnotation(term='near-IR'),OntologyAnnotation(term='far-IR'),OntologyAnnotation(term='UV')]\n",
    "            }),\n",
    "            ('raw_spectral_data_file', [\n",
    "                {\n",
    "                    'node_type': DATA_FILE,\n",
    "                    'size': 1,\n",
    "                    'technical_replicates': 2,\n",
    "                    'is_input_to_next_protocols': False\n",
    "                }\n",
    "            ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmr_assay_graph = AssayGraph.generate_assay_plan_from_dict(nmr_assay_dict)\n",
    "interspersed_sample_node = ProductNode(node_type=SAMPLE, name=\"sample qc\", \n",
    "                                       size=2,characteristics=(\n",
    "                                           Characteristic(category='dilution', value=10, unit='ml'),\n",
    "                                       ))\n",
    "pre_run_sample_node = ProductNode(node_type=SAMPLE, \n",
    "                                  name=\"pre run qc\",\n",
    "                                  size=2,\n",
    "                                  characteristics=(\n",
    "                                      Characteristic(category='dilution', value=10, unit='ml'),\n",
    "                                  ))\n",
    "\n",
    "qc_object = QualityControl(interspersed_sample_type=[(interspersed_sample_node, 10)], \n",
    "                           pre_run_sample_type=pre_run_sample_node)\n",
    "\n",
    "\n",
    "nmr_assay_graph.quality_control=qc_object\n",
    "\n",
    "sap1 = SampleAndAssayPlan(name=\"sap1\" , sample_plan=[input_material1],assay_plan=[nmr_assay_graph])\n",
    " \n",
    "sample2assay_plan={input_material1: [nmr_assay_graph]}\n",
    "\n",
    "sap1.sample_to_assay_map=sample2assay_plan\n",
    "\n",
    "sorted(sap1.assay_plan)[0].quality_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associating each `study arm` with the `study cell` and its `sample to assay plan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arm1.add_item_to_arm_map(st_cl1,sap1)\n",
    "arm2.add_item_to_arm_map(st_cl2,sap1)\n",
    "arm3.add_item_to_arm_map(st_cl3,sap1)\n",
    "arm4.add_item_to_arm_map(st_cl4,sap1)\n",
    "arm5.add_item_to_arm_map(st_cl5,sap1)\n",
    "arm6.add_item_to_arm_map(st_cl6,sap1)\n",
    "arm7.add_item_to_arm_map(st_cl7,sap1)\n",
    "arm8.add_item_to_arm_map(st_cl8,sap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding all the `study arm` to the `study design` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study_design= StudyDesign(name='parallel group design 2x2x2 #1')\n",
    "study_design.add_study_arm(arm1)\n",
    "study_design.add_study_arm(arm2)\n",
    "study_design.add_study_arm(arm3)\n",
    "study_design.add_study_arm(arm4)\n",
    "study_design.add_study_arm(arm5)\n",
    "study_design.add_study_arm(arm6)\n",
    "study_design.add_study_arm(arm7)\n",
    "study_design.add_study_arm(arm8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now serialize the ISA Study Design Object as a JSON document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "from isatools.create.model import StudyDesignEncoder\n",
    "\n",
    "f=json.dumps(study_design, cls=StudyDesignEncoder, sort_keys=True, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's produce a graphical representation of the study groups and their size using python bokeh library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Range1d, BoxAnnotation, Label, Legend, LegendItem, LabelSet\n",
    "from bokeh.models.tools import HoverTool\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "# hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_treatment_factors(some_element):\n",
    "    treat = \"\"\n",
    "    for j in range(len(some_element['factorValues'])):\n",
    "        if j < len(some_element['factorValues']) - 1:\n",
    "            if 'unit' in some_element['factorValues'][j].keys():\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \" \" \\\n",
    "                        + str(some_element['factorValues'][j]['unit']['term'].lower()) + \", \"\n",
    "            else:\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \",\"\n",
    "        else:\n",
    "            if 'unit' in some_element['factorValues'][j].keys():\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value']) + \" \" \\\n",
    "                        + str(some_element['factorValues'][j]['unit']['term'].lower())\n",
    "            else:\n",
    "                treat = treat + some_element['factorValues'][j]['factor']['name'].lower() + \": \" \\\n",
    "                        + str(some_element['factorValues'][j]['value'])\n",
    "\n",
    "    return treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "design = json.loads(json.dumps(study_design, cls=StudyDesignEncoder, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "frames = []\n",
    "Items = []\n",
    "\n",
    "# defining a color pallet for the different element types:\n",
    "element_colors = {\"biological intervention\": \"rgb(253,232,37)\",\n",
    "                  \"radiological intervention\": \"rgb(53, 155, 8)\",\n",
    "                  \"dietary intervention\": \"rgb(53, 155, 8)\",\n",
    "                  \"chemical intervention\": \"rgb(69, 13, 83)\",\n",
    "                  \"washout\": \"rgb(45, 62, 120)\",\n",
    "                  \"screen\": \"rgb(33, 144, 140)\",\n",
    "                  \"run in\": \"rgb(43, 144, 180)\",\n",
    "                  \"follow-up\": \"rgb(88, 189, 94)\",\n",
    "                  \"concomitant treatment\": \"rgb(255, 255, 0)\"}\n",
    "\n",
    "# processing the study design arms and treatment plans:\n",
    "for key in design[\"studyArms\"].keys():\n",
    "    DF = pd.DataFrame(columns=['Arm', 'Cell', 'Type', 'Start_date', 'End_date', 'Treatment', 'Color'])\n",
    "    arm_name = key\n",
    "    # print(\"arm: \", arm_name)\n",
    "    size = design[\"studyArms\"][key][\"groupSize\"]\n",
    "    size_annotation = \"n=\" + str(size)\n",
    "\n",
    "    cells_per_arm = design[\"studyArms\"][key][\"cells\"]\n",
    "    cell_counter = 0\n",
    "    for cell in cells_per_arm:\n",
    "        cell_name = cell['name']\n",
    "        elements_per_cell = cell['elements']\n",
    "\n",
    "        for element in elements_per_cell:\n",
    "            treat = \"\"\n",
    "            element_counter = 0                      \n",
    "            if 'concomitantTreatments' in element.keys():\n",
    "                element_counter = element_counter + 1\n",
    "                treatments = []\n",
    "                for item in element['concomitantTreatments']:\n",
    "                    treatment = get_treatment_factors(item)\n",
    "                    treatments.append(treatment)\n",
    "                    \n",
    "                concomitant = ','.join(treatments[0:-1])\n",
    "                concomitant = concomitant + ' and ' + treatments[-1]\n",
    "                array = [arm_name, cell_name, arm_name + \": [\" + concomitant + \"]_concomitant_\" + str(cell_counter),\n",
    "                     dt.datetime(cell_counter + 2000, 1, 1), dt.datetime(cell_counter + 2000 + 1, 1, 1),\n",
    "                     str(element['factorValues']),\n",
    "                     concomitant,\n",
    "                     element_colors[\"concomitant treatment\"]]\n",
    "                Items.append(array)\n",
    "\n",
    "            elif 'type' in element.keys():\n",
    "                treatment = get_treatment_factors(element)\n",
    "                element_counter = element_counter + 1\n",
    "                array = [arm_name, cell_name, arm_name + \": [\" + str(element['type']) + \"]_\" + str(cell_counter),\n",
    "                         dt.datetime((cell_counter + 2000), 1, 1), dt.datetime((cell_counter + 2000 + 1), 1, 1),\n",
    "                         # str(element['factorValues']),\n",
    "                         str(treatment),\n",
    "                         element_colors[element['type']]]\n",
    "                Items.append(array)\n",
    "\n",
    "            cell_counter = cell_counter + 1\n",
    "\n",
    "for i, Dat in enumerate(Items):\n",
    "    DF.loc[i] = Dat\n",
    "#     print(\"setting:\", DF.loc[i])\n",
    "\n",
    "# providing the canvas for the figure\n",
    "# print(\"THESE ARE THE TYPES_: \", DF.Type.tolist())\n",
    "fig = figure(title='Study Design Treatment Plan',\n",
    "             width=800,\n",
    "             height=400,\n",
    "             y_range=DF.Type.tolist(),\n",
    "             x_range=Range1d(DF.Start_date.min(), DF.End_date.max()),\n",
    "             tools='save')\n",
    "\n",
    "# adding a tool tip\n",
    "hover = HoverTool(tooltips=\"Task: @Type<br>\\\n",
    "Start: @Start_date<br>\\\n",
    "Cell_Name: @Cell<br>\\\n",
    "Treatment: @Treatment\")\n",
    "fig.add_tools(hover)\n",
    "\n",
    "DF['ID'] = DF.index+0.8\n",
    "# print(\"ID: \", DF['ID'])\n",
    "DF['ID1'] = DF.index+1.2\n",
    "# print(\"ID1: \", DF['ID1'])\n",
    "CDS = ColumnDataSource(DF)\n",
    "# , legend=str(size_annotation)\n",
    "r = fig.quad(left='Start_date', right='End_date', bottom='ID', top='ID1', source=CDS, color=\"Color\")\n",
    "fig.xaxis.axis_label = 'Time'\n",
    "fig.yaxis.axis_label = 'study arms'\n",
    "\n",
    "# working at providing a background color change for every arm in the study design\n",
    "counts = DF['Arm'].value_counts().tolist()\n",
    "# print(\"total number of study arms:\", len(counts), \"| number of phases per arm:\", counts)\n",
    "# box = []\n",
    "# for i, this_element in enumerate(DF['Arm']):\n",
    "#     if i==0:\n",
    "#         box[i] = BoxAnnotation(bottom=0,\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              fill_color=\"blue\")\n",
    "#     elif i % 2 == 0:\n",
    "#         box[i] = BoxAnnotation(bottom=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              fill_color=\"silver\")\n",
    "#     else:\n",
    "#         box[i] = BoxAnnotation(bottom=DF['Arm'].value_counts().tolist()[0],\n",
    "#                              top=DF['Arm'].value_counts().tolist()[0] + DF['Arm'].value_counts().tolist()[1],\n",
    "#                              fill_color=\"grey\",\n",
    "#                              fill_alpha=0.1)\n",
    "# # adding the background color for each arm:\n",
    "# for element in box:\n",
    "#     fig.add_layout(element)\n",
    "# # fig.add_layout(box2)\n",
    "# # fig.add_layout(legend,'right')\n",
    "\n",
    "caption1 = Legend(items=[(str(size_annotation), [r])])\n",
    "fig.add_layout(caption1, 'right')\n",
    "\n",
    "citation = Label(x=10, y=-80, x_units='screen', y_units='screen',\n",
    "                 text='parallel group design layout - isa-api 0.12', render_mode='css',\n",
    "                 border_line_color='gray', border_line_alpha=0.4,\n",
    "                 background_fill_color='white', background_fill_alpha=1.0)\n",
    "\n",
    "fig.add_layout(citation)\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now generate the full `ISA Study object` from the `ISA Study Design object`\n",
    "\n",
    "This is done by invoking the new `generate_isa_study` method on the ISA `study design` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = study_design.generate_isa_study()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now check the objects which have been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "investigation.studies=[study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(investigation.studies[0].assays[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also simply write to file either as ISA-Tab or as ISA-JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WRITING ISA-JSON document\n",
    "print(json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture # remove this line if you want to see printout  \n",
    "from isatools import isatab\n",
    "isatab.dump(investigation, './notebook-output/isa-2x2x2-single-measure-design')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One can also check out the tables as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isatools.isatab import dump_tables_to_dataframes as dumpdf\n",
    "dataframes = dumpdf(investigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes[list(dataframes.keys())[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or use the graph structure to count objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in study.assays[0].graph.nodes() if isinstance(study.assays[0].graph.indexes[x], Sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len([x for x in study.assays[0].graph.nodes() if isinstance(study.assays[0].graph.indexes[x], Sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[getattr(study.assays[0].graph.indexes[x], 'name', None) for x in study.assays[0].graph.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "- authors: philippe.rocca-serra@oerc.ox.ac.uk, massimiliano.izzo@oerc.ox.ac.uk\n",
    "- license: CC-BY 4.0\n",
    "- support: isatools@googlegroups.com\n",
    "- issue tracker: https://github.com/ISA-tools/isa-api/issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py39",
   "language": "python",
   "name": "isa-api-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
