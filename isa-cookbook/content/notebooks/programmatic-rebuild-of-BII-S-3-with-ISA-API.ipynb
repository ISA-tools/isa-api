{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmatic recreation of BII-S-3 with the ISA-API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "With this practical, we'll be showing how to use the ISA-API object to recreate programmatically the BII-S-3 dataset published in 2008 by Dr Jack Gilbert and colleagues.\n",
    "\n",
    "The practical demonstrates a so-called \"roundtrip\" exercice where:\n",
    "- Programmatically generated ISA objects are written (serialized) to disk in the ISA-Tab format.\n",
    "- The resulting output is then read back into memory by invoking the ISA-API load function. \n",
    "- The objects loaded in memory are serialized back out again and compared to the first output to ensure equivalent and integrity to demonstrate validity of the parsing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's start by loading the ISA-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isatools.model import (\n",
    "    Comment,\n",
    "    Investigation,\n",
    "    Study,\n",
    "    StudyFactor,\n",
    "    FactorValue,\n",
    "    OntologyAnnotation,\n",
    "    Characteristic,\n",
    "    OntologySource,\n",
    "    Material,\n",
    "    Sample,\n",
    "    Source,\n",
    "    Protocol,\n",
    "    ProtocolParameter,\n",
    "    ProtocolComponent,\n",
    "    ParameterValue,\n",
    "    Process,\n",
    "    Publication,\n",
    "    Person,\n",
    "    Assay,\n",
    "    DataFile,\n",
    "    plink\n",
    ")\n",
    "import datetime\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building the ISA objects for representing BII-S-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "investigation = Investigation()\n",
    "# i_comment = Comment(name=\"i_comment\", value=\"i_value\")\n",
    "# investigation.comments.append(i_comment)\n",
    "\n",
    "\n",
    "# Declaring the Ontologies and Vocabularies used in the ISA Study\n",
    "# dummy_onto=OntologySource(name=\"Dumbo\",description=\"\")\n",
    "chebi=OntologySource(name=\"CHEBI\",description=\"Chemical Entity of Biological Interest\")\n",
    "efo=OntologySource(name=\"EFO\", description=\"Experimental Factor Ontology\")\n",
    "obi = OntologySource(name='OBI', description=\"Ontology for Biomedical Investigations\")\n",
    "pato = OntologySource(name='PATO', description=\"Phenotype and Trait Ontology\")\n",
    "ncbitaxon = OntologySource(name=\"NCIBTaxon\", description=\"NCBI Taxonomy\")\n",
    "investigation.ontology_source_references=[chebi,efo,obi,pato,ncbitaxon]\n",
    "\n",
    "\n",
    "study = Study(filename=\"s_BII-S-3-synthesis.txt\")\n",
    "# st_comment = Comment(name=\"st_comment\", value=\"st_value\")\n",
    "# study.comments.append(st_comment)\n",
    "study.identifier = \"BII-S-3-synth\"\n",
    "study.title = \"Metagenomes and Metatranscriptomes of phytoplankton blooms from an ocean acidification mesocosm experiment\"\n",
    "study.description = \"Sequencing the metatranscriptome can provide information about the response of organisms to varying environmental conditions. We present a methodology for obtaining random whole-community mRNA from a complex microbial assemblage using Pyrosequencing. The metatranscriptome had, with minimum contamination by ribosomal RNA, significant coverage of abundant transcripts, and included significantly more potentially novel proteins than in the metagenome. This experiment is part of a much larger experiment. We have produced 4 454 metatranscriptomic datasets and 6 454 metagenomic datasets. These were derived from 4 samples.\"\n",
    "study.submission_date = \"15/08/2008\"\n",
    "study.public_release_date = \"15/08/2008\"\n",
    "\n",
    "# These NCBI SRA related ISA Comments fields are required and must be present for the ISA SRAconverter is to be invoked later\n",
    "src_comment_sra1 = Comment(name=\"SRA Broker Name\", value=\"OXFORD\")\n",
    "src_comment_sra2 = Comment(name=\"SRA Center Name\", value=\"OXFORD\")\n",
    "src_comment_sra3 = Comment(name=\"SRA Center Project Name\", value=\"OXFORD\")\n",
    "src_comment_sra4 = Comment(name=\"SRA Lab Name\", value=\"Oxford e-Research Centre\")\n",
    "src_comment_sra5 = Comment(name=\"SRA Submission Action\", value=\"ADD\")\n",
    "study.comments.append(src_comment_sra1)\n",
    "study.comments.append(src_comment_sra2)\n",
    "study.comments.append(src_comment_sra3)\n",
    "study.comments.append(src_comment_sra4)\n",
    "study.comments.append(src_comment_sra5)\n",
    "\n",
    "# These ISA Comments are optional and may be used to report funding information\n",
    "src_comment_st1 = Comment(name=\"Study Funding Agency\", value=\"\")\n",
    "src_comment_st2 = Comment(name=\"Study Grant Number\", value=\"\")\n",
    "study.comments.append(src_comment_st1)\n",
    "study.comments.append(src_comment_st2)\n",
    "   \n",
    "# Declaring all the protocols used in the ISA study. Note also the declaration of Protocol Parameters when needed.\n",
    "study.protocols = [ \n",
    "    Protocol(name=\"environmental material collection - standard procedure 1\",\n",
    "             description=\"Waters samples were prefiltered through a 1.6 um GF/A glass fibre filter to reduce Eukaryotic contamination. Filtrate was then collected on a 0.2 um Sterivex (millipore) filter which was frozen in liquid nitrogen until nucelic acid extraction. CO2 bubbled through 11000 L mesocosm to simulate ocean acidification predicted conditions. Then phosphate and nitrate were added to induce a phytoplankton bloom.\",\n",
    "             protocol_type=OntologyAnnotation(term=\"sample collection\"),\n",
    "             parameters=[\n",
    "              ProtocolParameter(parameter_name=OntologyAnnotation(term=\"filter pore size\"))\n",
    "             ]\n",
    "            ),\n",
    "    Protocol(name=\"aliquoting-0\", description=\"aliquoting\", protocol_type=OntologyAnnotation(term=\"sample collection\")),\n",
    "    Protocol(\n",
    "        name=\"nucleic acid extraction\",\n",
    "        description=\"Total nucleic acid extraction was done as quickly as possible using the method of Neufeld et al, 2007.\",\n",
    "        protocol_type=OntologyAnnotation(term=\"nucleic acid extraction\")\n",
    "    ),\n",
    "    Protocol(\n",
    "        name=\"mRNA extraction - standard procedure 3\",\n",
    "        description=\"RNA MinElute + substrative Hybridization + MEGAclear For transcriptomics, total RNA was separated from the columns using the RNA MinElute clean-up kit (Qiagen) and checked for integrity of rRNA using an Agilent bioanalyser (RNA nano6000 chip). High integrity rRNA is essential for subtractive hybridization. Samples were treated with Turbo DNA-free enzyme (Ambion) to remove contaminating DNA. The rRNA was removed from mRNA by subtractive hybridization (Microbe Express Kit, Ambion), and absence of rRNA and DNA contamination was confirmed using the Agilent bioanalyser. The mRNA was further purified with the MEGAclearTM kit (Ambion). Reverse transcription of mRNA was performed using the SuperScript III enzyme (Invitrogen) with random hexamer primers (Promega). The cDNA was treated with RiboShredderTM RNase Blend (Epicentre) to remove trace RNA contaminants. To improve the yield of cDNA, samples were subjected to random amplification using the GenomiPhi V2 method (GE Healthcare). GenomiPhi technology produces branched DNA molecules that are recalcitrant to the pyrosequencing methodology. Therefore amplified samples were treated with S1 nuclease using the method of Zhang et al.2006.\",\n",
    "        protocol_type=OntologyAnnotation(term=\"labeling\") #nucleic acid extraction\n",
    "    ),\n",
    "    Protocol(\n",
    "        name=\"genomic DNA extraction - standard procedure 4\",\n",
    "        description=\"superscript+random hexamer primer\",\n",
    "        protocol_type=OntologyAnnotation(term=\"nucleic acid extraction\")\n",
    "    ),\n",
    "    Protocol(\n",
    "        name=\"reverse transcription - standard procedure 5\",\n",
    "        description=\"\",\n",
    "        protocol_type=OntologyAnnotation(term=\"reverse transcription\"),\n",
    "    ),\n",
    "     Protocol(\n",
    "        name=\"library construction\",\n",
    "        description=\"\",\n",
    "        protocol_type=OntologyAnnotation(term=\"library construction\"),\n",
    "        parameters=[\n",
    "            ProtocolParameter(parameter_name=OntologyAnnotation(term=\"library strategy\")),\n",
    "            ProtocolParameter(parameter_name=OntologyAnnotation(term=\"library layout\")),\n",
    "            ProtocolParameter(parameter_name=OntologyAnnotation(term=\"library selection\"))\n",
    "        ]\n",
    "    ),   \n",
    "\n",
    "    Protocol(\n",
    "        name=\"nucleic acid sequencing\", #pyrosequencing - standard procedure 6\",\n",
    "        description=\"1. Sample Input and Fragmentation: The Genome Sequencer FLX System supports the sequencing of samples from a wide variety of starting materials including genomic DNA, PCR products, BACs, and cDNA. Samples such as genomic DNA and BACs are fractionated into small, 300- to 800-base pair fragments. For smaller samples, such as small non-coding RNA or PCR amplicons, fragmentation is not required. Instead, short PCR products amplified using Genome Sequencer fusion primers can be used for immobilization onto DNA capture beads as shown below.\",\n",
    "        protocol_type=OntologyAnnotation(term=\"nucleic acid sequencing\"),\n",
    "        parameters=[\n",
    "            ProtocolParameter(parameter_name=OntologyAnnotation(term=\"sequencing instrument\"))\n",
    "        ]\n",
    "    ),\n",
    "    Protocol(\n",
    "        name=\"sequence analysis - standard procedure 7\",\n",
    "        description=\"\",\n",
    "        protocol_type=OntologyAnnotation(term=\"data transformation\")\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Adding a Study Design descriptor to the ISA Study object\n",
    "intervention_design = OntologyAnnotation(term_source=obi)\n",
    "intervention_design.term = \"intervention design\"\n",
    "intervention_design.term_accession = \"http://purl.obolibrary.org/obo/OBI_0000115\"\n",
    "study.design_descriptors.append(intervention_design)\n",
    "\n",
    "\n",
    "# Declaring the Study Factors\n",
    "study.factors = [\n",
    "    StudyFactor(name=\"compound\",factor_type=OntologyAnnotation(term=\"chemical substance\",\n",
    "                                                              term_accession=\"http://purl.obolibrary.org/obo/CHEBI_59999\",\n",
    "                                                              term_source=chebi)),\n",
    "    StudyFactor(name=\"dose\",factor_type=OntologyAnnotation(term=\"dose\", term_accession=\"http://www.ebi.ac.uk/efo/EFO_0000428\",term_source=efo)),\n",
    "    StudyFactor(name=\"collection time\",factor_type=OntologyAnnotation(term=\"time\", term_accession=\"http://purl.obolibrary.org/obo/PATO_0000165\", term_source=pato))\n",
    "]\n",
    "\n",
    "# Associating the levels to each of the Study Factor.\n",
    "fv1 = FactorValue(factor_name=study.factors[0], value=OntologyAnnotation(term=\"carbon dioxide\"))\n",
    "fv2 = FactorValue(factor_name=study.factors[1], value=OntologyAnnotation(term=\"high\"))\n",
    "fv3 = FactorValue(factor_name=study.factors[1], value=OntologyAnnotation(term=\"normal\"))\n",
    "fv4 = FactorValue(factor_name=study.factors[2], value=\"may 13th, 2006\")\n",
    "fv5 = FactorValue(factor_name=study.factors[2], value=\"may 19th, 2006\")\n",
    "\n",
    "\n",
    "# Adding the publications associated to the study\n",
    "study.publications = [\n",
    "    Publication(doi=\"10.1371/journal.pone.0003042\",pubmed_id=\"18725995\",\n",
    "                title=\"Detection of large numbers of novel sequences in the metatranscriptomes of complex marine microbial communities.\",\n",
    "                status=OntologyAnnotation(term=\"indexed in PubMed\"),\n",
    "                author_list=\"Gilbert JA, Field D, Huang Y, Edwards R, Li W, Gilna P, Joint I.\"),\n",
    "    Publication(doi=\"10.1111/j.1462-2920.2008.01745.x\",\n",
    "                title=\"Potential for phosphonoacetate utilization by marine bacteria in temperate coastal waters\",\n",
    "               pubmed_id=\"18783384\",\n",
    "               status=OntologyAnnotation(term=\"indexed in PubMed\"),\n",
    "               author_list=\"Gilbert JA, Thomas S, Cooley NA, Kulakova A, Field D, Booth T, McGrath JW, Quinn JP, Joint I.\")   \n",
    "]\n",
    "\n",
    "\n",
    "# Adding the authors of the study\n",
    "study.contacts = [\n",
    "    Person(first_name=\"Jack\", last_name=\"Gilbert\", affiliation=\"Plymouth Marine Laboratory\", email=\"jagi@pml.ac.uk\",\n",
    "           address=\"Prospect Place, Plymouth, United Kingdom\",\n",
    "           comments=[Comment(name=\"Study Person REF\", value=\"\")],\n",
    "            roles=[OntologyAnnotation(term=\"principal investigator role\"),\n",
    "                   OntologyAnnotation(term=\"SRA Inform On Status\"),\n",
    "                   OntologyAnnotation(term=\"SRA Inform On Error\")]\n",
    "    ),\n",
    "    Person(first_name=\"Dawn\", last_name=\"Field\", affiliation=\"NERC Centre for Ecology and Hydrology\",\n",
    "           address=\"CEH Oxford, Oxford, United Kingdom\",\n",
    "           comments=[Comment(name=\"Study Person REF\", value=\"\")],\n",
    "           roles=[OntologyAnnotation(term=\"principal investigator role\")]\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, creating ISA Source and Sample objects and building what is the BII-S-3 Study table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study.sources = [Source(name=\"GSM255770\"), Source(name=\"GSM255771\"),Source(name=\"GSM255772\"),Source(name=\"GSM255773\")]\n",
    "study.samples = [Sample(name=\"GSM255770\"), Sample(name=\"GSM255771\"), Sample(name=\"GSM255772\"), Sample(name=\"GSM255773\")]\n",
    "\n",
    "# Note how the treatment groups are defined as sets of factor values attached to the ISA.Sample object\n",
    "study.samples[0].factor_values=[fv1,fv2,fv4]\n",
    "study.samples[1].factor_values=[fv1,fv3,fv4]\n",
    "study.samples[2].factor_values=[fv1,fv2,fv5]\n",
    "study.samples[3].factor_values=[fv1,fv3,fv5]\n",
    "\n",
    "characteristic_organism = Characteristic(category=OntologyAnnotation(term=\"Organism\"),\n",
    "                                     value=OntologyAnnotation(term=\"marine metagenome\", term_source=ncbitaxon,\n",
    "                                                              term_accession=\"http://purl.obolibrary.org/obo/NCBITaxon_408172\"))\n",
    "\n",
    "\n",
    "# Now creating a Process showing a `Protocol Application` using Source as input and producing Sample as output.\n",
    "for i in range(len(study.sources)):\n",
    "    \n",
    "    study.sources[i].characteristics.append(characteristic_organism)\n",
    "\n",
    "\n",
    "    study.process_sequence.append(Process(executes_protocol=study.protocols[0],\n",
    "                                         inputs=[study.sources[i]],\n",
    "                                         outputs=[study.samples[i]])\n",
    "                                                  )\n",
    "\n",
    "# Now appending the ISA Study object to the ISA Investigation object    \n",
    "investigation.studies = [study]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, creating the ISA objects to represent assays and acquired raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Starting by declaring the 2 types of assays used in BII-S-3 as coded with ISAcreator tool\n",
    "assay = Assay(filename=\"a_gilbert-assay-Gx.txt\")\n",
    "assay.measurement_type = OntologyAnnotation(term=\"metagenome sequencing\",term_accession=\"http://purl.obolibrary.org/obo/OBI_0002623\", term_source=obi)\n",
    "assay.technology_type = OntologyAnnotation(term=\"nucleotide sequencing\", term_accession=\"http://purl.obolibrary.org/obo/OBI_0000626\", term_source=obi)\n",
    "# assay.technology_type = OntologyAnnotation(term=\"\")\n",
    "\n",
    "\n",
    "\n",
    "assay_tx = Assay(filename=\"a_gilbert-assay-Tx.txt\")\n",
    "assay_tx.measurement_type = OntologyAnnotation(term=\"transcription profiling\",term_accession=\"http://purl.obolibrary.org/obo/OBI_0000424\", term_source=obi)\n",
    "assay_tx.technology_type = OntologyAnnotation(term=\"nucleotide sequencing\",term_accession=\"http://purl.obolibrary.org/obo/OBI_0000626\", term_source=obi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**warning**\n",
    "make sure the plink function connects the first and last protocol in a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, sample in enumerate(study.samples):\n",
    "    \n",
    "#     # create an aliquoting process which creates new samples from existing samples created in a study.processSequence\n",
    "#     aliquoting_process = Process(executes_protocol=study.protocols[1])\n",
    "#     aliquot = Sample(name=\"aliquot-{}\".format(i), derives_from=sample)\n",
    "#     aliquoting_process.inputs.append(sample)\n",
    "#     aliquoting_process.outputs.append(aliquot)\n",
    "\n",
    "    # create an extraction process that executes the extraction protocol\n",
    "\n",
    "    extraction_process = Process(executes_protocol=study.protocols[0])\n",
    "\n",
    "    # extraction process takes as input a sample, and produces an extract material as output\n",
    "    \n",
    "    char_ext = Characteristic(category=OntologyAnnotation(term=\"Material Type\"),\n",
    "                                     value=OntologyAnnotation(term=\"pellet\"))\n",
    "    \n",
    "    char_ext1 = Characteristic(category=OntologyAnnotation(term=\"quantity\"),\n",
    "                                     value=OntologyAnnotation(term=\"loads\"))\n",
    "\n",
    "    # extraction_process.inputs.append(aliquot)\n",
    "    extraction_process.inputs.append(sample)\n",
    "    material = Material(name=\"extract-{}\".format(i))\n",
    "    material.type = \"Extract Name\"\n",
    "    material.characteristics.append(char_ext)\n",
    "    material.characteristics.append(char_ext1)\n",
    "    extraction_process.outputs.append(material)\n",
    "\n",
    "    # create a sequencing process that executes the sequencing protocol\n",
    "\n",
    "    sequencing_process = Process(executes_protocol=study.protocols[7])\n",
    "    sequencing_process.name = \"assay-name-{}\".format(i)\n",
    "    sequencing_process.inputs.append(extraction_process.outputs[0])\n",
    "    # sequencing_process.inputs.append(material)\n",
    "\n",
    "    # Sequencing process usually has an output data file\n",
    "\n",
    "    datafile = DataFile(filename=\"sequenced-data-{}\".format(i), label=\"Raw Data File\")\n",
    "    data_comment = Comment(name=\"data_comment\",value=\"data_value\")\n",
    "    datafile.comments.append(data_comment)\n",
    "    sequencing_process.outputs.append(datafile)\n",
    "\n",
    "    # Ensure Processes are linked forward and backward. plink(from_process, to_process) is a function to set\n",
    "    # these links for you. It is found in the isatools.model package\n",
    "\n",
    "    # plink(aliquoting_process, sequencing_process)\n",
    "    plink(extraction_process, sequencing_process)\n",
    "    # make sure the extract, data file, and the processes are attached to the assay\n",
    "\n",
    "\n",
    "    assay.samples.append(sample)\n",
    "    # assay.samples.append(aliquot)\n",
    "    assay.other_material.append(material)\n",
    "    assay.data_files.append(datafile)\n",
    "    \n",
    "    assay.process_sequence.append(extraction_process)\n",
    "    assay.process_sequence.append(sequencing_process)\n",
    "\n",
    "    # create an extraction process that executes the extraction protocol\n",
    "\n",
    "    extraction_process_tx = Process(executes_protocol=study.protocols[2])\n",
    "\n",
    "    # extraction process takes as input a sample, and produces an extract material as output\n",
    "\n",
    "    extraction_process_tx.inputs.append(sample)\n",
    "    # extraction_process_tx.outputs.append(sample)\n",
    "    # extraction_process_tx.outputs=[]\n",
    "    # material_tx = Material(name=\"extract-{}\".format(i))\n",
    "    # material_tx.type = \"Extract Name\"\n",
    "    # extraction_process_tx.outputs.append(material_tx)\n",
    "\n",
    "    # labeling process takes as input an extract, and produces a labeled extract material as output\n",
    "    labeling_process_tx = Process(executes_protocol=study.protocols[3])\n",
    "    # labeling_process_tx.inputs.append(sample)\n",
    "    # labeling_process_tx.inputs=[]\n",
    "    material_tx = Material(name=\"le-{}\".format(i))\n",
    "    material_tx.type = \"Labeled Extract Name\"\n",
    "    labeling_process_tx.outputs.append(material_tx)\n",
    "    \n",
    "    \n",
    "    # create a sequencing process that executes the sequencing protocol\n",
    "    # seq_pv1 = ParameterValue(category=\"library layout\", value=\"SINGLE\")\n",
    "    seq_pv2 = ParameterValue(category=ProtocolParameter(parameter_name=OntologyAnnotation(term=\"library layout\")), value=OntologyAnnotation(term=\"SINGLE\"))\n",
    "    sequencing_process_tx = Process(executes_protocol=study.protocols[6], parameter_values=[seq_pv2])\n",
    "    sequencing_process_tx.name = \"assay-name-tx-{}\".format(i)\n",
    "    sequencing_process_tx.inputs.append(labeling_process_tx.outputs[0])\n",
    "\n",
    "    # Sequencing process usually has an output data file\n",
    "    \n",
    "    datafile_tx = DataFile(filename=\"sequenced-data-tx-{}\".format(i), label=\"Raw Data File\")\n",
    "    sequencing_process_tx.outputs.append(datafile_tx)\n",
    "\n",
    "    # Ensure Processes are linked forward and backward. plink(from_process, to_process) is a function to set\n",
    "    # these links for you. It is found in the isatools.model package\n",
    "\n",
    "   \n",
    "    # plink(extraction_process_tx, labeling_process_tx)\n",
    "    # plink(labeling_process_tx, sequencing_process_tx)\n",
    "    plink(extraction_process_tx, sequencing_process_tx)\n",
    "    # make sure the extract, data file, and the processes are attached to the assay\n",
    "\n",
    "\n",
    "    assay_tx.samples.append(sample)\n",
    "    assay_tx.other_material.append(material_tx)\n",
    "    assay_tx.data_files.append(datafile_tx)\n",
    "    \n",
    "    assay_tx.process_sequence.append(extraction_process_tx)\n",
    "    assay_tx.process_sequence.append(labeling_process_tx) \n",
    "    assay_tx.process_sequence.append(sequencing_process_tx)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding both assays to the ISA Study object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study.assays.append(assay)\n",
    "study.assays.append(assay_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from isatools import isatab\n",
    "# print(isatab.dumps(investigation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assay_g = investigation.studies[0].assays[1]\n",
    "# assay_t = investigation.studies[0].assays[0]\n",
    "\n",
    "# assay_t.samples=investigation.studies[0].samples\n",
    "\n",
    "\n",
    "# extract1 = Material(name=\"GSM255770.e1\")\n",
    "# extract1.type = \"Extract Name\"\n",
    "# extract2 = Material(name=\"GSM255771.e1\")\n",
    "# extract2.type = \"Extract Name\"\n",
    "# extract3 = Material(name=\"GSM255772.e1\")\n",
    "# extract3.type = \"Extract Name\"\n",
    "# extract4 = Material(name=\"GSM255773.e1\")\n",
    "# extract4.type = \"Extract Name\"\n",
    "# extract5 = Material(name=\"GSM255774.e1\")\n",
    "# extract5.type = \"Extract Name\"\n",
    "\n",
    "# assay_t.other_material.append(extract1)\n",
    "# assay_t.other_material.append(extract2)\n",
    "# assay_t.other_material.append(extract3)\n",
    "# assay_t.other_material.append(extract4)\n",
    "# assay_t.other_material.append(extract5)\n",
    "\n",
    "\n",
    "# for i in range(len(study.samples)):\n",
    "\n",
    "#     assay_t.process_sequence.append(Process(\n",
    "#             executes_protocol=study.protocols[1],\n",
    "#                 inputs=study.samples[i],\n",
    "#                 outputs=assay_t.other_material[i]\n",
    "#         ))\n",
    "    \n",
    "#     data=DataFile(filename=\"sequenced-data-{}\".format(i), label=\"Raw Data File\")  \n",
    "    \n",
    "#     assay_t.process_sequence.append(Process(\n",
    "#         executes_protocol=study.protocols[3],\n",
    "#                 inputs=assay_t.other_material[i]\n",
    "#     ))\n",
    "    \n",
    "#     plink(assay_t.process_sequence[0], assay_t.process_sequence[1])\n",
    "#     assay_t.process_sequence[-1].outputs.append(data)\n",
    "#     assay_t.data_files.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the ISA object representation to file with the ISA-API `dump` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isatools.isatab import dump\n",
    "\n",
    "# note the use of the flag for explicit serialization on factor values on assay tables\n",
    "dump(investigation, \"./output/BII-S-3-synth/\", write_factor_values_in_assay_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the ISA document from disk back in, loading it into memory and writing to disk again to check that the ISA-API load function works nominally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from isatools.isatab import load\n",
    "with open(os.path.join(\"./output/BII-S-3-synth/\",\"i_investigation.txt\")) as bii3stest:\n",
    "    roundtrip = load(bii3stest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the use of the flag for explicit serialization on factor values on assay tables\n",
    "dump(roundtrip, \"./notebook-output/BII-S-3-roundtrip/\", write_factor_values_in_assay_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the output of each serialization and checking for equivalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import hashlib\n",
    "\n",
    "# hashlib.md5(open(os.path.join(\"./output/\",\"i_investigation.txt\")).read()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import filecmp\n",
    "\n",
    "filecmp.cmp('./output/BII-S-3-synth/i_investigation.txt', './notebook-output/BII-S-3-roundtrip/i_investigation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filecmp.cmp('./output/BII-S-3-synth/s_BII-S-3-synthesis.txt', './notebook-output/BII-S-3-roundtrip/s_BII-S-3-synthesis.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filecmp.cmp('./output/BII-S-3-synth/a_gilbert-assay-Gx.txt', './notebook-output/BII-S-3-roundtrip/a_gilbert-assay-Gx.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filecmp.cmp('./output/BII-S-3-synth/a_gilbert-assay-Tx.txt', './notebook-output/BII-S-3-roundtrip/a_gilbert-assay-Tx.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "While the `i_investigation.txt` files are identical, the other comparisons return `False` indicating that they  are not exactly identical.\n",
    "\n",
    "The cause of the difference is simply down to the order in which `FactorValues` are serialized. This is caused by the underlying data structure used to store this information but the the information is equivalent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "- authors: philippe.rocca-serra@oerc.ox.ac.uk\n",
    "- license: CC-BY 4.0\n",
    "- support: isatools@googlegroups.com\n",
    "- issue tracker: https://github.com/ISA-tools/isa-api/issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isa-api-py39",
   "language": "python",
   "name": "isa-api-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
